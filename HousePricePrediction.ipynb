{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousePricePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwGJ-vhbujb",
        "colab_type": "code",
        "outputId": "0d858dc8-d6ea-432c-bdba-74a19fb00985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model, Sequential\n",
        "from keras.metrics import mean_absolute_error, mae, mse\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.regularizers import l2, l1_l2\n",
        "\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1v4zYdqej0k",
        "colab_type": "code",
        "outputId": "c099d59b-e682-4f82-8c2f-8fcfaf70c29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erff7ShwIGKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(url, columns=[1, 2, 4, 6, 11]):\n",
        "  df = pd.read_csv(url, header=None, usecols=columns)\n",
        "  print('Data shape: ', np.shape(df))\n",
        "\n",
        "  # re-name all columns\n",
        "  column_names = ['Price', 'PurchaseDate', 'PropertyType', 'LeaseDuration', 'City']\n",
        "  df.columns = column_names\n",
        "  \n",
        "  # resplace column values\n",
        "  df['PropertyType'] = df['PropertyType'].replace({'F':0, 'D':1, 'S':2, 'T':3, 'O':4})\n",
        "  df['LeaseDuration'] = df['LeaseDuration'].replace({'L':0, 'F':1, 'U':2})\n",
        "  df.loc[df['City']=='LONDON', 'City'] = 0\n",
        "  df.loc[df['City'] != 0, 'City'] = 1\n",
        "\n",
        "  # convert column values to appropriate dtype to save memory\n",
        "  df['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'])\n",
        "  df['Price'] = pd.to_numeric(df[\"Price\"], downcast=\"integer\")\n",
        "  df['PropertyType'] = pd.to_numeric(df['PropertyType'], downcast='integer')\n",
        "  df['LeaseDuration'] = pd.to_numeric(df[\"LeaseDuration\"], downcast=\"integer\")\n",
        "  df['City'] = pd.to_numeric(df[\"City\"], downcast=\"integer\")\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXQfJ7yd3P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(df):\n",
        "  cutoff = datetime(2016, 1, 1)\n",
        "  column_sels = ['Price', 'PropertyType', 'LeaseDuration', 'City']\n",
        "  train_df = df.loc[df['PurchaseDate'] <= cutoff][column_sels]\n",
        "  test_df = df.loc[df['PurchaseDate'] > cutoff][column_sels] \n",
        "  \n",
        "  # remove duplicates\n",
        "  train_df.drop_duplicates(keep='first', inplace=True)\n",
        "  test_df.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "  return train_df, test_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kI469W9I02n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(train_df):\n",
        "  # split to train and val (~20%)\n",
        "  train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=2019)\n",
        "  print(\"Train shape : \", train_df.shape)\n",
        "  print(\"Test shape : \", test_df.shape)\n",
        "  \n",
        "  return train_df, val_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "807FFQwiJW8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep(train_df, val_df, test_df):\n",
        "  # training data\n",
        "  train_X = train_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  train_y = train_df['Price']\n",
        "\n",
        "  val_X = val_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  val_y = val_df['Price']\n",
        "\n",
        "  # testing data\n",
        "  test_X = test_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  test_y = test_df['Price']\n",
        "\n",
        "  # one-hot encoding the inputs\n",
        "  ohc = OneHotEncoder(handle_unknown='ignore')\n",
        "  ohc.fit(train_X)\n",
        "  train_X = ohc.transform(train_X)\n",
        "  val_X = ohc.transform(val_X)\n",
        "  test_X = ohc.transform(test_X)\n",
        "\n",
        "  # convert the targets to smaller range\n",
        "  train_y = np.log1p(train_y * 1e-3)\n",
        "  val_y = np.log1p(val_y * 1e-3)\n",
        "  test_y = np.log1p(test_y * 1e-3)\n",
        "\n",
        "  return (train_X, train_y), (val_X, val_y), (test_X, test_y)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur0vmdiu1IDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_size):\n",
        "  \"\"\" Build the model with many fully connected layers  \n",
        "  \"\"\"\n",
        "  inp = Input(shape=(input_size,))\n",
        "  fc1 = Dense(100, activation='relu', kernel_regularizer=l2(0.001))(inp)\n",
        "  do1 = Dropout(0.5)(fc1)\n",
        "  fc2 = Dense(200, activation='relu', kernel_regularizer=l2(0.001))(do1)\n",
        "  do2 = Dropout(0.5)(fc2)\n",
        "  fc3 = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(do2)\n",
        "  do3 = Dropout(0.5)(fc3)\n",
        "  fc4 = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(do3)\n",
        "  out = Dense(1)(fc4)\n",
        "\n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(optimizer=RMSprop(lr=1e-3), loss=mse, metrics=[mae])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwzVEw54HPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, epochs=10, b_size=10000):\n",
        "  \"\"\" Perform model traning  \n",
        "  \"\"\"\n",
        "  history = model.fit(train_X, train_y, batch_size=b_size, verbose=1,\n",
        "                      epochs=epochs, validation_data=(val_X, val_y))\n",
        "  \n",
        "  train_mae = history.history['mean_absolute_error']\n",
        "  val_mae = history.history['val_mean_absolute_error']\n",
        "  \n",
        "  return train_mae, val_mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKWXA96351JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_val_error_plotter(train_mae, val_mae):\n",
        "  \"\"\" Plot the train/val loss over epochs\n",
        "  \"\"\"\n",
        "  epochs = len(train_mae)\n",
        "  plt.plot(range(1, epochs+1), train_mae, label='Training Loss')\n",
        "  plt.plot(range(1, epochs+1), val_mae, label='Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw_71SZg63Ei",
        "colab_type": "code",
        "outputId": "260f8c46-823e-4f39-e3fc-31b5dbe971e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = '/content/drive/My Drive/pp-complete.csv'\n",
        "\n",
        "df = load_data(url)\n",
        "train_df, test_df = split_train_test(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape:  (24852949, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0r8CEzb9UGt",
        "colab_type": "code",
        "outputId": "3527a4af-5cdb-4fac-aa93-2fcd7042a042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fitting the model using cross validation with k folds\n",
        "k = 5\n",
        "num_samples = np.shape(train_df)[0] // k\n",
        "num_epochs = 50\n",
        "b_size = 512\n",
        "train_errors = []\n",
        "val_errors = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold {0}'.format(i))\n",
        "  val_data = train_df.iloc[i*num_samples:(i+1)*num_samples]\n",
        "  train_data = pd.concat([train_df.iloc[:i*num_samples], train_df.iloc[(i+1)*num_samples:]])\n",
        "\n",
        "  (train_X, train_y), (val_X, val_y), (test_X, test_y) = prep(train_data, val_data, test_df)\n",
        "  model = build_model(np.shape(train_X)[1])\n",
        "  train_mae, val_mae = train_model(model, num_epochs, b_size)\n",
        "  train_errors.append(train_mae)\n",
        "  val_errors.append(val_mae)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "254362/254362 [==============================] - 8s 33us/step - loss: 3.3545 - mean_absolute_error: 1.0219 - val_loss: 2.0650 - val_mean_absolute_error: 0.7883\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.7308 - mean_absolute_error: 0.7953 - val_loss: 2.7014 - val_mean_absolute_error: 1.3019\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2160 - mean_absolute_error: 0.7468 - val_loss: 1.9883 - val_mean_absolute_error: 1.1252\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0794 - mean_absolute_error: 0.7328 - val_loss: 1.8273 - val_mean_absolute_error: 1.0861\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0336 - mean_absolute_error: 0.7264 - val_loss: 2.0134 - val_mean_absolute_error: 1.1564\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0276 - mean_absolute_error: 0.7263 - val_loss: 1.9983 - val_mean_absolute_error: 1.1490\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0249 - mean_absolute_error: 0.7260 - val_loss: 2.1836 - val_mean_absolute_error: 1.2196\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0240 - mean_absolute_error: 0.7262 - val_loss: 1.9076 - val_mean_absolute_error: 1.1237\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0212 - mean_absolute_error: 0.7255 - val_loss: 2.0260 - val_mean_absolute_error: 1.1624\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0203 - mean_absolute_error: 0.7257 - val_loss: 1.9170 - val_mean_absolute_error: 1.1247\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0200 - mean_absolute_error: 0.7256 - val_loss: 1.9741 - val_mean_absolute_error: 1.1462\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7253 - val_loss: 1.9593 - val_mean_absolute_error: 1.1441\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7250 - val_loss: 1.9202 - val_mean_absolute_error: 1.1287\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7247 - val_loss: 2.1075 - val_mean_absolute_error: 1.1923\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0161 - mean_absolute_error: 0.7248 - val_loss: 2.1747 - val_mean_absolute_error: 1.2133\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0137 - mean_absolute_error: 0.7245 - val_loss: 2.0973 - val_mean_absolute_error: 1.1885\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0150 - mean_absolute_error: 0.7249 - val_loss: 2.3106 - val_mean_absolute_error: 1.2604\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0138 - mean_absolute_error: 0.7244 - val_loss: 2.0239 - val_mean_absolute_error: 1.1617\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0137 - mean_absolute_error: 0.7247 - val_loss: 2.1605 - val_mean_absolute_error: 1.2083\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0135 - mean_absolute_error: 0.7243 - val_loss: 2.2691 - val_mean_absolute_error: 1.2522\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0122 - mean_absolute_error: 0.7243 - val_loss: 2.1055 - val_mean_absolute_error: 1.1947\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0131 - mean_absolute_error: 0.7242 - val_loss: 2.0382 - val_mean_absolute_error: 1.1632\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0126 - mean_absolute_error: 0.7244 - val_loss: 1.8901 - val_mean_absolute_error: 1.1186\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0129 - mean_absolute_error: 0.7245 - val_loss: 2.0101 - val_mean_absolute_error: 1.1598\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0121 - mean_absolute_error: 0.7244 - val_loss: 1.9934 - val_mean_absolute_error: 1.1518\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0109 - mean_absolute_error: 0.7243 - val_loss: 1.7894 - val_mean_absolute_error: 1.0804\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0114 - mean_absolute_error: 0.7242 - val_loss: 1.9428 - val_mean_absolute_error: 1.1340\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0102 - mean_absolute_error: 0.7241 - val_loss: 2.1746 - val_mean_absolute_error: 1.2105\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0081 - mean_absolute_error: 0.7240 - val_loss: 2.0574 - val_mean_absolute_error: 1.1746\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0094 - mean_absolute_error: 0.7239 - val_loss: 1.8889 - val_mean_absolute_error: 1.1164\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0095 - mean_absolute_error: 0.7242 - val_loss: 1.9320 - val_mean_absolute_error: 1.1348\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0093 - mean_absolute_error: 0.7242 - val_loss: 2.0778 - val_mean_absolute_error: 1.1841\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0097 - mean_absolute_error: 0.7244 - val_loss: 2.0978 - val_mean_absolute_error: 1.1892\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0093 - mean_absolute_error: 0.7240 - val_loss: 2.0175 - val_mean_absolute_error: 1.1602\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0094 - mean_absolute_error: 0.7243 - val_loss: 2.1557 - val_mean_absolute_error: 1.2077\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0091 - mean_absolute_error: 0.7238 - val_loss: 1.9862 - val_mean_absolute_error: 1.1501\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0098 - mean_absolute_error: 0.7243 - val_loss: 1.8905 - val_mean_absolute_error: 1.1153\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0082 - mean_absolute_error: 0.7242 - val_loss: 2.0864 - val_mean_absolute_error: 1.1886\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0077 - mean_absolute_error: 0.7239 - val_loss: 1.9533 - val_mean_absolute_error: 1.1401\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0082 - mean_absolute_error: 0.7243 - val_loss: 2.3963 - val_mean_absolute_error: 1.2844\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0075 - mean_absolute_error: 0.7238 - val_loss: 2.1031 - val_mean_absolute_error: 1.1999\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0065 - mean_absolute_error: 0.7237 - val_loss: 1.9433 - val_mean_absolute_error: 1.1362\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0075 - mean_absolute_error: 0.7238 - val_loss: 1.8749 - val_mean_absolute_error: 1.1120\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0078 - mean_absolute_error: 0.7240 - val_loss: 2.0416 - val_mean_absolute_error: 1.1699\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0061 - mean_absolute_error: 0.7239 - val_loss: 2.2738 - val_mean_absolute_error: 1.2505\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0068 - mean_absolute_error: 0.7239 - val_loss: 2.1674 - val_mean_absolute_error: 1.2189\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0063 - mean_absolute_error: 0.7238 - val_loss: 1.7660 - val_mean_absolute_error: 1.0650\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0065 - mean_absolute_error: 0.7241 - val_loss: 2.1691 - val_mean_absolute_error: 1.2163\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0060 - mean_absolute_error: 0.7239 - val_loss: 2.0275 - val_mean_absolute_error: 1.1689\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0067 - mean_absolute_error: 0.7237 - val_loss: 1.9914 - val_mean_absolute_error: 1.1533\n",
            "processing fold 1\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 16us/step - loss: 3.4311 - mean_absolute_error: 1.0535 - val_loss: 1.8213 - val_mean_absolute_error: 0.7261\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.8224 - mean_absolute_error: 0.8498 - val_loss: 1.3340 - val_mean_absolute_error: 0.8147\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.3685 - mean_absolute_error: 0.8128 - val_loss: 1.0665 - val_mean_absolute_error: 0.7572\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2451 - mean_absolute_error: 0.8003 - val_loss: 1.0848 - val_mean_absolute_error: 0.7956\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2049 - mean_absolute_error: 0.7948 - val_loss: 1.1063 - val_mean_absolute_error: 0.8101\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1992 - mean_absolute_error: 0.7944 - val_loss: 1.0584 - val_mean_absolute_error: 0.7883\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1947 - mean_absolute_error: 0.7934 - val_loss: 1.1567 - val_mean_absolute_error: 0.8368\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1918 - mean_absolute_error: 0.7927 - val_loss: 1.0692 - val_mean_absolute_error: 0.7953\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1909 - mean_absolute_error: 0.7929 - val_loss: 1.1118 - val_mean_absolute_error: 0.8168\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1886 - mean_absolute_error: 0.7927 - val_loss: 1.0959 - val_mean_absolute_error: 0.8084\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1892 - mean_absolute_error: 0.7930 - val_loss: 1.1255 - val_mean_absolute_error: 0.8246\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1873 - mean_absolute_error: 0.7926 - val_loss: 1.1454 - val_mean_absolute_error: 0.8335\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1875 - mean_absolute_error: 0.7928 - val_loss: 1.0691 - val_mean_absolute_error: 0.7971\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1854 - mean_absolute_error: 0.7923 - val_loss: 1.0665 - val_mean_absolute_error: 0.7948\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1854 - mean_absolute_error: 0.7924 - val_loss: 1.1285 - val_mean_absolute_error: 0.8266\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1833 - mean_absolute_error: 0.7919 - val_loss: 1.1535 - val_mean_absolute_error: 0.8382\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1857 - mean_absolute_error: 0.7924 - val_loss: 1.0652 - val_mean_absolute_error: 0.7961\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1835 - mean_absolute_error: 0.7923 - val_loss: 1.0650 - val_mean_absolute_error: 0.7966\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1816 - mean_absolute_error: 0.7917 - val_loss: 1.0518 - val_mean_absolute_error: 0.7889\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1836 - mean_absolute_error: 0.7923 - val_loss: 1.0944 - val_mean_absolute_error: 0.8112\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1838 - mean_absolute_error: 0.7924 - val_loss: 1.0599 - val_mean_absolute_error: 0.7949\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1836 - mean_absolute_error: 0.7926 - val_loss: 1.0947 - val_mean_absolute_error: 0.8108\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1847 - mean_absolute_error: 0.7923 - val_loss: 1.1093 - val_mean_absolute_error: 0.8181\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1820 - mean_absolute_error: 0.7922 - val_loss: 1.1886 - val_mean_absolute_error: 0.8551\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1815 - mean_absolute_error: 0.7921 - val_loss: 1.1919 - val_mean_absolute_error: 0.8557\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1818 - mean_absolute_error: 0.7923 - val_loss: 1.0885 - val_mean_absolute_error: 0.8083\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1810 - mean_absolute_error: 0.7920 - val_loss: 1.0964 - val_mean_absolute_error: 0.8131\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1822 - mean_absolute_error: 0.7922 - val_loss: 1.1523 - val_mean_absolute_error: 0.8391\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1814 - mean_absolute_error: 0.7921 - val_loss: 1.0498 - val_mean_absolute_error: 0.7900\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1809 - mean_absolute_error: 0.7922 - val_loss: 1.1763 - val_mean_absolute_error: 0.8498\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1801 - mean_absolute_error: 0.7919 - val_loss: 1.1440 - val_mean_absolute_error: 0.8352\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1811 - mean_absolute_error: 0.7920 - val_loss: 1.1700 - val_mean_absolute_error: 0.8467\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1802 - mean_absolute_error: 0.7921 - val_loss: 1.2228 - val_mean_absolute_error: 0.8707\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1815 - mean_absolute_error: 0.7923 - val_loss: 1.0678 - val_mean_absolute_error: 0.7987\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1803 - mean_absolute_error: 0.7921 - val_loss: 1.1162 - val_mean_absolute_error: 0.8229\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1777 - mean_absolute_error: 0.7913 - val_loss: 1.1913 - val_mean_absolute_error: 0.8566\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1790 - mean_absolute_error: 0.7919 - val_loss: 1.0373 - val_mean_absolute_error: 0.7848\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1789 - mean_absolute_error: 0.7918 - val_loss: 1.1474 - val_mean_absolute_error: 0.8373\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1797 - mean_absolute_error: 0.7922 - val_loss: 1.1263 - val_mean_absolute_error: 0.8271\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1780 - mean_absolute_error: 0.7917 - val_loss: 1.1583 - val_mean_absolute_error: 0.8423\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1795 - mean_absolute_error: 0.7919 - val_loss: 1.1079 - val_mean_absolute_error: 0.8196\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1796 - mean_absolute_error: 0.7921 - val_loss: 1.1073 - val_mean_absolute_error: 0.8186\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1780 - mean_absolute_error: 0.7920 - val_loss: 1.1701 - val_mean_absolute_error: 0.8475\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1767 - mean_absolute_error: 0.7914 - val_loss: 1.0653 - val_mean_absolute_error: 0.7971\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1776 - mean_absolute_error: 0.7916 - val_loss: 1.2013 - val_mean_absolute_error: 0.8622\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1770 - mean_absolute_error: 0.7917 - val_loss: 1.1335 - val_mean_absolute_error: 0.8308\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1780 - mean_absolute_error: 0.7920 - val_loss: 1.1569 - val_mean_absolute_error: 0.8414\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1778 - mean_absolute_error: 0.7913 - val_loss: 1.1083 - val_mean_absolute_error: 0.8188\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1765 - mean_absolute_error: 0.7915 - val_loss: 1.1684 - val_mean_absolute_error: 0.8465\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1778 - mean_absolute_error: 0.7919 - val_loss: 1.1108 - val_mean_absolute_error: 0.8206\n",
            "processing fold 2\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 16us/step - loss: 3.4995 - mean_absolute_error: 1.0781 - val_loss: 1.8848 - val_mean_absolute_error: 0.8125\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.8585 - mean_absolute_error: 0.8848 - val_loss: 1.0667 - val_mean_absolute_error: 0.6880\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.4498 - mean_absolute_error: 0.8557 - val_loss: 0.8193 - val_mean_absolute_error: 0.6262\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.3323 - mean_absolute_error: 0.8463 - val_loss: 0.7649 - val_mean_absolute_error: 0.6267\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2874 - mean_absolute_error: 0.8410 - val_loss: 0.7662 - val_mean_absolute_error: 0.6352\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2785 - mean_absolute_error: 0.8395 - val_loss: 0.7714 - val_mean_absolute_error: 0.6426\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2741 - mean_absolute_error: 0.8390 - val_loss: 0.7674 - val_mean_absolute_error: 0.6397\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2733 - mean_absolute_error: 0.8396 - val_loss: 0.7811 - val_mean_absolute_error: 0.6507\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2712 - mean_absolute_error: 0.8387 - val_loss: 0.7667 - val_mean_absolute_error: 0.6410\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2690 - mean_absolute_error: 0.8389 - val_loss: 0.7633 - val_mean_absolute_error: 0.6402\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2696 - mean_absolute_error: 0.8389 - val_loss: 0.7973 - val_mean_absolute_error: 0.6625\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2701 - mean_absolute_error: 0.8394 - val_loss: 0.7421 - val_mean_absolute_error: 0.6270\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2672 - mean_absolute_error: 0.8386 - val_loss: 0.7890 - val_mean_absolute_error: 0.6600\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2669 - mean_absolute_error: 0.8387 - val_loss: 0.8132 - val_mean_absolute_error: 0.6704\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2661 - mean_absolute_error: 0.8383 - val_loss: 0.7897 - val_mean_absolute_error: 0.6586\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2659 - mean_absolute_error: 0.8381 - val_loss: 0.7419 - val_mean_absolute_error: 0.6291\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2643 - mean_absolute_error: 0.8381 - val_loss: 0.7551 - val_mean_absolute_error: 0.6377\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2636 - mean_absolute_error: 0.8382 - val_loss: 0.7657 - val_mean_absolute_error: 0.6420\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2641 - mean_absolute_error: 0.8381 - val_loss: 0.7664 - val_mean_absolute_error: 0.6461\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2635 - mean_absolute_error: 0.8384 - val_loss: 0.8143 - val_mean_absolute_error: 0.6733\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2611 - mean_absolute_error: 0.8379 - val_loss: 0.7443 - val_mean_absolute_error: 0.6317\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2631 - mean_absolute_error: 0.8381 - val_loss: 0.7839 - val_mean_absolute_error: 0.6554\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2623 - mean_absolute_error: 0.8382 - val_loss: 0.7587 - val_mean_absolute_error: 0.6423\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2612 - mean_absolute_error: 0.8377 - val_loss: 0.7581 - val_mean_absolute_error: 0.6408\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2620 - mean_absolute_error: 0.8379 - val_loss: 0.7503 - val_mean_absolute_error: 0.6341\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2608 - mean_absolute_error: 0.8376 - val_loss: 0.7559 - val_mean_absolute_error: 0.6376\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2612 - mean_absolute_error: 0.8382 - val_loss: 0.7711 - val_mean_absolute_error: 0.6491\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2607 - mean_absolute_error: 0.8377 - val_loss: 0.7355 - val_mean_absolute_error: 0.6215\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2613 - mean_absolute_error: 0.8380 - val_loss: 0.7643 - val_mean_absolute_error: 0.6454\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2600 - mean_absolute_error: 0.8377 - val_loss: 0.7602 - val_mean_absolute_error: 0.6448\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2598 - mean_absolute_error: 0.8376 - val_loss: 0.7440 - val_mean_absolute_error: 0.6318\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2600 - mean_absolute_error: 0.8379 - val_loss: 0.7685 - val_mean_absolute_error: 0.6478\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2568 - mean_absolute_error: 0.8373 - val_loss: 0.7591 - val_mean_absolute_error: 0.6411\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2608 - mean_absolute_error: 0.8378 - val_loss: 0.7497 - val_mean_absolute_error: 0.6337\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2581 - mean_absolute_error: 0.8376 - val_loss: 0.7530 - val_mean_absolute_error: 0.6372\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2594 - mean_absolute_error: 0.8378 - val_loss: 0.7510 - val_mean_absolute_error: 0.6399\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2577 - mean_absolute_error: 0.8375 - val_loss: 0.7474 - val_mean_absolute_error: 0.6333\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2578 - mean_absolute_error: 0.8372 - val_loss: 0.7326 - val_mean_absolute_error: 0.6253\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2585 - mean_absolute_error: 0.8380 - val_loss: 0.7746 - val_mean_absolute_error: 0.6525\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2588 - mean_absolute_error: 0.8381 - val_loss: 0.7505 - val_mean_absolute_error: 0.6380\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2578 - mean_absolute_error: 0.8371 - val_loss: 0.7773 - val_mean_absolute_error: 0.6531\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2572 - mean_absolute_error: 0.8376 - val_loss: 0.7406 - val_mean_absolute_error: 0.6308\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2574 - mean_absolute_error: 0.8374 - val_loss: 0.7829 - val_mean_absolute_error: 0.6563\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2569 - mean_absolute_error: 0.8374 - val_loss: 0.7651 - val_mean_absolute_error: 0.6450\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2562 - mean_absolute_error: 0.8375 - val_loss: 0.7417 - val_mean_absolute_error: 0.6302\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2572 - mean_absolute_error: 0.8373 - val_loss: 0.7426 - val_mean_absolute_error: 0.6327\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2546 - mean_absolute_error: 0.8367 - val_loss: 0.8082 - val_mean_absolute_error: 0.6706\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2547 - mean_absolute_error: 0.8368 - val_loss: 0.7834 - val_mean_absolute_error: 0.6579\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2573 - mean_absolute_error: 0.8376 - val_loss: 0.7594 - val_mean_absolute_error: 0.6429\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2561 - mean_absolute_error: 0.8373 - val_loss: 0.7348 - val_mean_absolute_error: 0.6284\n",
            "processing fold 3\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 17us/step - loss: 3.4648 - mean_absolute_error: 1.0828 - val_loss: 2.0436 - val_mean_absolute_error: 0.8935\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.8234 - mean_absolute_error: 0.8868 - val_loss: 0.9928 - val_mean_absolute_error: 0.6471\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.4266 - mean_absolute_error: 0.8585 - val_loss: 0.7612 - val_mean_absolute_error: 0.5869\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.3231 - mean_absolute_error: 0.8490 - val_loss: 0.9167 - val_mean_absolute_error: 0.7003\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2829 - mean_absolute_error: 0.8430 - val_loss: 0.9019 - val_mean_absolute_error: 0.6994\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2744 - mean_absolute_error: 0.8415 - val_loss: 0.8553 - val_mean_absolute_error: 0.6749\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2702 - mean_absolute_error: 0.8412 - val_loss: 0.9602 - val_mean_absolute_error: 0.7339\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2707 - mean_absolute_error: 0.8417 - val_loss: 0.9086 - val_mean_absolute_error: 0.7034\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2667 - mean_absolute_error: 0.8408 - val_loss: 0.8416 - val_mean_absolute_error: 0.6683\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2656 - mean_absolute_error: 0.8414 - val_loss: 0.8298 - val_mean_absolute_error: 0.6628\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2645 - mean_absolute_error: 0.8408 - val_loss: 0.7947 - val_mean_absolute_error: 0.6466\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2620 - mean_absolute_error: 0.8404 - val_loss: 0.7835 - val_mean_absolute_error: 0.6396\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2608 - mean_absolute_error: 0.8405 - val_loss: 0.8889 - val_mean_absolute_error: 0.6959\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2614 - mean_absolute_error: 0.8404 - val_loss: 0.8428 - val_mean_absolute_error: 0.6728\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2610 - mean_absolute_error: 0.8406 - val_loss: 0.8070 - val_mean_absolute_error: 0.6542\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2599 - mean_absolute_error: 0.8403 - val_loss: 0.9079 - val_mean_absolute_error: 0.7111\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2597 - mean_absolute_error: 0.8402 - val_loss: 0.7824 - val_mean_absolute_error: 0.6404\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2583 - mean_absolute_error: 0.8398 - val_loss: 0.8131 - val_mean_absolute_error: 0.6581\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2575 - mean_absolute_error: 0.8399 - val_loss: 0.8126 - val_mean_absolute_error: 0.6577\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2589 - mean_absolute_error: 0.8402 - val_loss: 0.8484 - val_mean_absolute_error: 0.6797\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2573 - mean_absolute_error: 0.8401 - val_loss: 0.8723 - val_mean_absolute_error: 0.6917\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2572 - mean_absolute_error: 0.8405 - val_loss: 0.8642 - val_mean_absolute_error: 0.6855\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2570 - mean_absolute_error: 0.8401 - val_loss: 0.7927 - val_mean_absolute_error: 0.6442\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2557 - mean_absolute_error: 0.8395 - val_loss: 0.9749 - val_mean_absolute_error: 0.7458\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2556 - mean_absolute_error: 0.8399 - val_loss: 0.8142 - val_mean_absolute_error: 0.6626\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2569 - mean_absolute_error: 0.8399 - val_loss: 0.7628 - val_mean_absolute_error: 0.6279\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2545 - mean_absolute_error: 0.8395 - val_loss: 0.8452 - val_mean_absolute_error: 0.6757\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2564 - mean_absolute_error: 0.8400 - val_loss: 0.9050 - val_mean_absolute_error: 0.7097\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2536 - mean_absolute_error: 0.8396 - val_loss: 0.8749 - val_mean_absolute_error: 0.6924\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2534 - mean_absolute_error: 0.8396 - val_loss: 0.7255 - val_mean_absolute_error: 0.6115\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2534 - mean_absolute_error: 0.8396 - val_loss: 0.8236 - val_mean_absolute_error: 0.6640\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2535 - mean_absolute_error: 0.8397 - val_loss: 0.7915 - val_mean_absolute_error: 0.6461\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2536 - mean_absolute_error: 0.8397 - val_loss: 0.6914 - val_mean_absolute_error: 0.5915\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2526 - mean_absolute_error: 0.8395 - val_loss: 0.8493 - val_mean_absolute_error: 0.6811\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2526 - mean_absolute_error: 0.8397 - val_loss: 0.8340 - val_mean_absolute_error: 0.6716\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2524 - mean_absolute_error: 0.8396 - val_loss: 0.8694 - val_mean_absolute_error: 0.6901\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2540 - mean_absolute_error: 0.8396 - val_loss: 0.8609 - val_mean_absolute_error: 0.6860\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2514 - mean_absolute_error: 0.8390 - val_loss: 0.8646 - val_mean_absolute_error: 0.6884\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2524 - mean_absolute_error: 0.8393 - val_loss: 0.9201 - val_mean_absolute_error: 0.7171\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2521 - mean_absolute_error: 0.8393 - val_loss: 0.7289 - val_mean_absolute_error: 0.6092\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2499 - mean_absolute_error: 0.8388 - val_loss: 0.8716 - val_mean_absolute_error: 0.6926\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2527 - mean_absolute_error: 0.8399 - val_loss: 0.7469 - val_mean_absolute_error: 0.6233\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2507 - mean_absolute_error: 0.8397 - val_loss: 0.8481 - val_mean_absolute_error: 0.6804\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2521 - mean_absolute_error: 0.8397 - val_loss: 0.8148 - val_mean_absolute_error: 0.6592\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2501 - mean_absolute_error: 0.8393 - val_loss: 0.7994 - val_mean_absolute_error: 0.6507\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2507 - mean_absolute_error: 0.8395 - val_loss: 0.9267 - val_mean_absolute_error: 0.7219\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2501 - mean_absolute_error: 0.8391 - val_loss: 0.7565 - val_mean_absolute_error: 0.6293\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2481 - mean_absolute_error: 0.8389 - val_loss: 0.8151 - val_mean_absolute_error: 0.6590\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2502 - mean_absolute_error: 0.8392 - val_loss: 0.7905 - val_mean_absolute_error: 0.6495\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2496 - mean_absolute_error: 0.8390 - val_loss: 0.8284 - val_mean_absolute_error: 0.6675\n",
            "processing fold 4\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 17us/step - loss: 3.0815 - mean_absolute_error: 0.9926 - val_loss: 4.8144 - val_mean_absolute_error: 1.6906\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.5238 - mean_absolute_error: 0.7987 - val_loss: 2.3776 - val_mean_absolute_error: 1.0813\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1294 - mean_absolute_error: 0.7681 - val_loss: 2.1731 - val_mean_absolute_error: 1.0490\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0302 - mean_absolute_error: 0.7567 - val_loss: 2.2799 - val_mean_absolute_error: 1.0996\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0074 - mean_absolute_error: 0.7535 - val_loss: 2.3131 - val_mean_absolute_error: 1.1122\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0031 - mean_absolute_error: 0.7535 - val_loss: 2.1766 - val_mean_absolute_error: 1.0606\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0013 - mean_absolute_error: 0.7529 - val_loss: 2.3899 - val_mean_absolute_error: 1.1432\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0009 - mean_absolute_error: 0.7533 - val_loss: 2.3903 - val_mean_absolute_error: 1.1392\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0006 - mean_absolute_error: 0.7535 - val_loss: 2.4037 - val_mean_absolute_error: 1.1453\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9998 - mean_absolute_error: 0.7532 - val_loss: 2.4256 - val_mean_absolute_error: 1.1541\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9977 - mean_absolute_error: 0.7532 - val_loss: 2.5893 - val_mean_absolute_error: 1.2115\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9979 - mean_absolute_error: 0.7533 - val_loss: 2.5415 - val_mean_absolute_error: 1.1962\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9972 - mean_absolute_error: 0.7529 - val_loss: 2.3409 - val_mean_absolute_error: 1.1232\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9969 - mean_absolute_error: 0.7530 - val_loss: 2.5138 - val_mean_absolute_error: 1.1876\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9957 - mean_absolute_error: 0.7528 - val_loss: 2.2099 - val_mean_absolute_error: 1.0762\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9965 - mean_absolute_error: 0.7531 - val_loss: 2.4681 - val_mean_absolute_error: 1.1717\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9959 - mean_absolute_error: 0.7529 - val_loss: 2.4433 - val_mean_absolute_error: 1.1615\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9952 - mean_absolute_error: 0.7529 - val_loss: 2.3445 - val_mean_absolute_error: 1.1268\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9950 - mean_absolute_error: 0.7529 - val_loss: 2.4667 - val_mean_absolute_error: 1.1679\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9951 - mean_absolute_error: 0.7527 - val_loss: 2.3063 - val_mean_absolute_error: 1.1110\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9945 - mean_absolute_error: 0.7528 - val_loss: 2.5300 - val_mean_absolute_error: 1.1919\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9945 - mean_absolute_error: 0.7529 - val_loss: 2.3615 - val_mean_absolute_error: 1.1320\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9943 - mean_absolute_error: 0.7529 - val_loss: 2.2061 - val_mean_absolute_error: 1.0781\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9933 - mean_absolute_error: 0.7528 - val_loss: 2.3237 - val_mean_absolute_error: 1.1159\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9930 - mean_absolute_error: 0.7526 - val_loss: 2.3522 - val_mean_absolute_error: 1.1282\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9933 - mean_absolute_error: 0.7532 - val_loss: 2.3508 - val_mean_absolute_error: 1.1290\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9928 - mean_absolute_error: 0.7529 - val_loss: 2.5111 - val_mean_absolute_error: 1.1849\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9932 - mean_absolute_error: 0.7530 - val_loss: 2.4126 - val_mean_absolute_error: 1.1515\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9917 - mean_absolute_error: 0.7524 - val_loss: 2.4207 - val_mean_absolute_error: 1.1524\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9922 - mean_absolute_error: 0.7526 - val_loss: 2.4510 - val_mean_absolute_error: 1.1637\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9915 - mean_absolute_error: 0.7527 - val_loss: 2.4052 - val_mean_absolute_error: 1.1491\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9921 - mean_absolute_error: 0.7527 - val_loss: 2.3601 - val_mean_absolute_error: 1.1307\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9917 - mean_absolute_error: 0.7527 - val_loss: 2.3726 - val_mean_absolute_error: 1.1376\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9914 - mean_absolute_error: 0.7527 - val_loss: 2.3869 - val_mean_absolute_error: 1.1400\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9912 - mean_absolute_error: 0.7523 - val_loss: 2.5076 - val_mean_absolute_error: 1.1845\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9910 - mean_absolute_error: 0.7524 - val_loss: 2.3727 - val_mean_absolute_error: 1.1369\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9911 - mean_absolute_error: 0.7525 - val_loss: 2.4817 - val_mean_absolute_error: 1.1757\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9907 - mean_absolute_error: 0.7526 - val_loss: 2.3739 - val_mean_absolute_error: 1.1374\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9893 - mean_absolute_error: 0.7522 - val_loss: 2.3445 - val_mean_absolute_error: 1.1274\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9900 - mean_absolute_error: 0.7526 - val_loss: 2.3696 - val_mean_absolute_error: 1.1352\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9903 - mean_absolute_error: 0.7526 - val_loss: 2.4366 - val_mean_absolute_error: 1.1593\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 0.9892 - mean_absolute_error: 0.7523 - val_loss: 2.4786 - val_mean_absolute_error: 1.1746\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9898 - mean_absolute_error: 0.7526 - val_loss: 2.5960 - val_mean_absolute_error: 1.2158\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9894 - mean_absolute_error: 0.7524 - val_loss: 2.5067 - val_mean_absolute_error: 1.1850\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9895 - mean_absolute_error: 0.7525 - val_loss: 2.4750 - val_mean_absolute_error: 1.1736\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9884 - mean_absolute_error: 0.7520 - val_loss: 2.2768 - val_mean_absolute_error: 1.1010\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9880 - mean_absolute_error: 0.7519 - val_loss: 2.2608 - val_mean_absolute_error: 1.0959\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9901 - mean_absolute_error: 0.7526 - val_loss: 2.3940 - val_mean_absolute_error: 1.1470\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9876 - mean_absolute_error: 0.7519 - val_loss: 2.3521 - val_mean_absolute_error: 1.1296\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9884 - mean_absolute_error: 0.7521 - val_loss: 2.2820 - val_mean_absolute_error: 1.1026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0oNXD0wZjUJ",
        "colab_type": "code",
        "outputId": "b1240bf3-f868-45e3-e880-a2ddb603b1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_errors[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi0BN6UdZv0F",
        "colab_type": "code",
        "outputId": "89033a29-e95f-47d3-adc8-805914598682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "avg_train = [np.mean(i) for i in zip(*train_errors)]\n",
        "avg_val = [np.mean(i) for i in zip(*val_errors)]\n",
        "training_val_error_plotter(avg_train, avg_val)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcsChDHGmLAsQBhjjAnr/wOPRclpe7NJMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ1L1C19a7Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous*factor + point*(1-factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDkFfd1ja8ou",
        "colab_type": "code",
        "outputId": "5896dba5-a89a-43a4-b1e3-291859572bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "smooth_avg_val = smooth_curve(avg_val, factor=0.5)\n",
        "training_val_error_plotter(avg_train, smooth_avg_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU9bn48c8zk0kmYQkEUFYJCiph\nh4grIloVcUGUIlQQV1prq7VqS73e6vVq6+31p2jdbXG7ClJxQUWtVVyoGwFZFEQQQTZZBVlCksk8\nvz++Z8IkzGSfTMg87xfzmpkzZ855znBynvNdzveIqmKMMcZU5Et2AMYYYxonSxDGGGNisgRhjDEm\nJksQxhhjYrIEYYwxJqa0ZAdQX9q2bau5ubnJDsMYYw4q8+fP36qq7WJ91mQSRG5uLgUFBckOwxhj\nDioisibeZ1bFZIwxJiZLEMYYY2JKWIIQkakisllEvojzuYjI/SKyUkQWi8jAqM9KRWSh95iVqBiN\nMcbEl8g2iCeBB4Cn43x+FtDDexwLPOw9AxSqav8ExmaMqaWSkhLWrVvHvn37kh2KqYFgMEjnzp0J\nBALV/k7CEoSqfiAiuZXMMhJ4Wt1gUJ+ISCsR6aCqGxMVkzGm7tatW0eLFi3Izc1FRJIdjqkGVWXb\ntm2sW7eObt26Vft7yWyD6ASsjXq/zpsGEBSRAhH5RETOj7cAEZnkzVewZcuWRMZqjPHs27ePNm3a\nWHI4iIgIbdq0qXGpr7E2UndV1XzgZ8AUETki1kyq+piq5qtqfrt2MbvxGmMSwJLDwac2/2fJTBDr\ngS5R7zt701DVyPMq4D1gQKKC2F0U4p63v2bh2h2JWoUxxhyUkpkgZgGXeL2ZjgN2qupGEWktIhkA\nItIWOBFYmqggSkJh7n9nBQu/+yFRqzDG1KNt27bRv39/+vfvT/v27enUqVPZ++Li4mot47LLLmP5\n8uWVzvPggw/y7LPP1kfInHTSSSxcuLBeltWQEtZILSLTgFOAtiKyDrgVCACo6iPAbGAEsBLYC1zm\nfbUn8KiIhHEJ7C5VTViCyEz3A1BYEk7UKowx9ahNmzZlB9vbbruN5s2bc+ONN5abR1VRVXy+2OfA\nTzzxRJXrueaaa+oe7EEuYSUIVR2nqh1UNaCqnVX176r6iJccUOcaVT1CVfuoaoE3/SPvfT/v+e+J\nihEgI82HCBQWhxK5GmNMgq1cuZK8vDwuvvhievXqxcaNG5k0aRL5+fn06tWL22+/vWzeyBl9KBSi\nVatWTJ48mX79+nH88cezefNmAG655RamTJlSNv/kyZMZPHgwRx11FB999BEAe/bs4cILLyQvL4/R\no0eTn59f7ZJCYWEhEydOpE+fPgwcOJAPPvgAgCVLlnDMMcfQv39/+vbty6pVq9i1axdnnXUW/fr1\no3fv3rzwwgv1+dPF1WTGYqotESEz4KewpDTZoRhz0PmvV79k6YYf63WZeR1bcuu5vWr13a+++oqn\nn36a/Px8AO666y5ycnIIhUIMGzaM0aNHk5eXV+47O3fuZOjQodx111389re/ZerUqUyePPmAZasq\nn332GbNmzeL222/nzTff5K9//Svt27dn5syZLFq0iIEDBx7wvXjuv/9+MjIyWLJkCV9++SUjRoxg\nxYoVPPTQQ9x4441cdNFFFBUVoaq88sor5Obm8sYbb5TF3BAaay+mBmUJwpim4YgjjihLDgDTpk1j\n4MCBDBw4kGXLlrF06YG11ZmZmZx11lkADBo0iNWrV8dc9gUXXHDAPHPnzmXs2LEA9OvXj169qp/Y\n5s6dy/jx4wHo1asXHTt2ZOXKlZxwwgnccccd/OUvf2Ht2rUEg0H69u3Lm2++yeTJk/n3v/9NdnZ2\ntddTFylfggAIBvwUFlsbhDE1Vdsz/URp1qxZ2esVK1Zw33338dlnn9GqVSvGjx8f8zqA9PT0std+\nv59QKHZ1c0ZGRpXz1IcJEyZw/PHH8/rrrzN8+HCmTp3KySefTEFBAbNnz2by5MmcddZZ3HzzzQmL\nIcJKEEBWup99VoIwpkn58ccfadGiBS1btmTjxo289dZb9b6OE088kRkzZgCu7SBWCSWeIUOGlPWS\nWrZsGRs3bqR79+6sWrWK7t27c91113HOOeewePFi1q9fT/PmzZkwYQI33HADCxYsqPdticVKELie\nTHutkdqYJmXgwIHk5eVx9NFH07VrV0488cR6X8evf/1rLrnkEvLy8soe8ap/zjzzzLJxkIYMGcLU\nqVP5+c9/Tp8+fQgEAjz99NOkp6fz3HPPMW3aNAKBAB07duS2227jo48+YvLkyfh8PtLT03nkkUfq\nfVtiETcU0sEvPz9fa3vDoDGPfoxPYPqk4+s5KmOanmXLltGzZ89kh9EohEIhQqEQwWCQFStWcMYZ\nZ7BixQrS0hrnuXes/zsRme+NXHGAxrkVDSwz4GdHYUmywzDGHGR2797NaaedRigUQlV59NFHG21y\nqI2msyV1kBnw8/1OG7rYGFMzrVq1Yv78+ckOI2GskRrXSG3dXI0xpjxLEEAw3c/eYksQxhgTzRIE\nrorJurkaY0x5liDYfyV1U+nRZYwx9cESBO46iNKwUlJqCcKYxm7YsGEHXPQ2ZcoUrr766kq/17x5\ncwA2bNjA6NGjY85zyimnUFV3+SlTprB3796y9yNGjGDHjrrfT+a2227j7rvvrvNy6pMlCFwJArCG\namMOAuPGjWP69Onlpk2fPp1x48ZV6/sdO3as02ioFRPE7NmzadWqVa2X15hZgiDqnhDWUG1Mozd6\n9Ghef/31spsDrV69mg0bNjBkyJCy6xIGDhxInz59eOWVVw74/urVq+nduzfghtweO3YsPXv2ZNSo\nURQWFpbNd/XVV5cNFX7rrbcCbgTWDRs2MGzYMIYNGwZAbm4uW7duBeCee+6hd+/e9O7du2yo8NWr\nV9OzZ0+uuuoqevXqxRlnnFFuPVWJtcw9e/Zw9tlnlw3//fzzzwMwefJk8vLy6Nu37wH3yKgNuw4C\nK0EYU2tvTIbvl9TvMtv3gbPuivtxTk4OgwcP5o033mDkyJFMnz6dMWPGICIEg0FeeuklWrZsydat\nWznuuOM477zz4t6P+eGHHyYrK4tly5axePHicsN133nnneTk5FBaWsppp53G4sWLufbaa7nnnnuY\nM2cObdu2Lbes+fPn88QTT/Dpp5+iqhx77LEMHTqU1q1bs2LFCqZNm8bjjz/OmDFjmDlzZtlIrpWJ\nt8xVq1bRsWNHXn/9dcAN/71t2zZeeuklvvrqK0SkXqq9rASBG80VrARhzMEiupopunpJVbn55pvp\n27cvP/nJT1i/fj2bNm2Ku5wPPvig7EDdt29f+vbtW/bZjBkzGDhwIAMGDODLL7+sciC+uXPnMmrU\nKJo1a0bz5s254IIL+PDDDwHo1q0b/fv3ByofUry6y+zTpw9vv/02v//97/nwww/Jzs4mOzubYDDI\nFVdcwYsvvkhWVla11lEZK0EQfdtRSxDG1EglZ/qJNHLkSK6//noWLFjA3r17GTRoEADPPvssW7Zs\nYf78+QQCAXJzc2MO8V2Vb7/9lrvvvpt58+bRunVrLr300lotJyIyVDi44cJrUsUUy5FHHsmCBQuY\nPXs2t9xyC6eddhp//OMf+eyzz3jnnXd44YUXeOCBB3j33XfrtB4rQeCupAbsWghjDhLNmzdn2LBh\nXH755eUap3fu3MkhhxxCIBBgzpw5rFmzptLlnHzyyTz33HMAfPHFFyxevBhwQ4U3a9aM7OxsNm3a\nVHYnN4AWLVqwa9euA5Y1ZMgQXn75Zfbu3cuePXt46aWXGDJkSJ22M94yN2zYQFZWFuPHj+emm25i\nwYIF7N69m507dzJixAjuvfdeFi1aVKd1g5UggP1tEHY1tTEHj3HjxjFq1KhyPZouvvhizj33XPr0\n6UN+fj5HH310pcu4+uqrueyyy+jZsyc9e/YsK4n069ePAQMGcPTRR9OlS5dyQ4VPmjSJ4cOH07Fj\nR+bMmVM2feDAgVx66aUMHjwYgCuvvJIBAwZUuzoJ4I477ihriAZYt25dzGW+9dZb3HTTTfh8PgKB\nAA8//DC7du1i5MiR7Nu3D1XlnnvuqfZ647HhvoGVm3fzk3ve5/5xAzivX8d6jsyYpsWG+z541XS4\nb6tiYn8bxD4rQRhjTBlLEFg3V2OMicUSBPsbqS1BGFM9TaVqOpXU5v/MEgSQkeZ+BmukNqZqwWCQ\nbdu2WZI4iKgq27ZtIxgM1uh71osJEBEb8tuYaurcuTPr1q1jy5YtyQ7F1EAwGKRz5841+o4lCE9m\nut+upDamGgKBAN26dUt2GKYBWBWTJ3JPCGOMMY4lCE8w4LMEYYwxURKWIERkqohsFpEv4nwuInK/\niKwUkcUiMjDqs4kissJ7TExUjNGy0tOsiskYY6IksgTxJDC8ks/PAnp4j0nAwwAikgPcChwLDAZu\nFZHWCYwT8KqYLEEYY0yZhCUIVf0A2F7JLCOBp9X5BGglIh2AM4G3VXW7qv4AvE3liaZeBNOtDcIY\nY6Ilsw2iE7A26v06b1q86QcQkUkiUiAiBXXtcpcZ8Fk3V2OMiXJQN1Kr6mOqmq+q+e3atavTsqwX\nkzHGlJfMBLEe6BL1vrM3Ld70hMpMT7MrqY0xJkoyE8Qs4BKvN9NxwE5V3Qi8BZwhIq29xukzvGkJ\nlRnw22iuxhgTJWFXUovINOAUoK2IrMP1TAoAqOojwGxgBLAS2Atc5n22XUT+G5jnLep2Va2ssbte\nZKbbdRDGGBMtYQlCVcdV8bkC18T5bCowNRFxxZMZ8BMKKyWlYQL+g7ppxhhj6oUdCT1BuyeEMcaU\nYwnCk5XuClN2sZwxxjiWIDyZ6e6nsARhjDGOJQiP3XbUGGPKswThsTYIY4wpzxKEJ1KCsGshjDHG\nsQThiTRS29XUxhjjWILYvQVevoacLZ8AVsVkjDERdk/q9GawaBotAjnAcZYgjDHGYyWI9Cw4NI/g\n5oUANuS3McZ4LEEAdMon8P3nCGG7DsIYYzyWIAA65yNFuzhcNlojtTHGeCxBAHTKB+CYwCqrYjLG\nGI8lCIC2PSC9BQN931gjtTHGeCxBAPj80GkAfWWltUEYY4zHEkREp3y66xpCRXuTHYkxxjQKliAi\nOueTRintdi9PdiTGGNMoWIKI6DQIgC6FS5MciDHGNA6WICJatGervx25+5YlOxJjjGkULEFEWRPs\nSfcSq2IyxhiwBFHOuqw8OoQ3wZ6tyQ7FGGOSzhJElO9b9HIv1hUkNxBjjGkELEFE2dYyjxA+WD8/\n2aEYY0zSWYKIkhZszgrtAuutBGGMMZYgomQG/Hxeeji6fj6Ew8kOxxhjksoSRJTMdD8LtTuybyds\nX5XscIwxJqksQUTJTPezMNzdvbFqJmNMirMEESUz4GeldiIcaGY9mYwxKc8SRJTMgJ8wPgrb9bUS\nhDEm5VmCiBJM9wOwu00/+P4LKNmX5IiMMSZ5EpogRGS4iCwXkZUiMjnG511F5B0RWSwi74lI56jP\nSkVkofeYlcg4IzIDLkH80LovhEvg+yUNsVpjjGmUEpYgRMQPPAicBeQB40Qkr8JsdwNPq2pf4Hbg\nz1GfFapqf+9xXqLijJbllSC2Zvd2E6yayRiTwhJZghgMrFTVVapaDEwHRlaYJw9413s9J8bnDSpS\ngtgRaActOtoV1caYlJbIBNEJWBv1fp03Ldoi4ALv9SighYi08d4HRaRARD4RkfNjrUBEJnnzFGzZ\nsqXOAQe9BFFYXAqdB1lPJmNMSkt2I/WNwFAR+RwYCqwHIjeF7qqq+cDPgCkickTFL6vqY6qar6r5\n7dq1q3MwmV4V076SUuiUDz98C3u21Xm5xhhzMEpkglgPdIl639mbVkZVN6jqBao6APgPb9oO73m9\n97wKeA8YkMBYgf1VTHuLS8vuMMeGBYlerTHGNEqJTBDzgB4i0k1E0oGxQLneSCLSVkQiMfwBmOpN\nby0iGZF5gBOBhN8LNJIgCktKoeMAEJ9VMxljUlbCEoSqhoBfAW8By4AZqvqliNwuIpFeSacAy0Xk\na+BQ4E5vek+gQEQW4Rqv71LVhCcIn0/ISPO5BJHRHNp0h01fJHq1xhjTKKUlcuGqOhuYXWHaH6Ne\nvwC8EON7HwF9EhlbPJnpfvYVe80gOUfA9m+TEYYxxiRdshupG53MgN+VIAByDncN1arJDcoYY5LA\nEkQFmQG/a6QGyOkGJXth96bkBmWMMUlgCaKCzHS/6+YKrgQBdm8IY0xKsgRRQfkqpm7u2RKEMSYF\nWYKoIDPd766kBsg+DHxpliCMMSnJEkQFwYCfwhLvftT+NGh1mCUIY0xKsgRRQWbAT2FxaP+EnMOt\nq6sxJiVZgqggKz2qDQL2Jwjr6mqMSTGWICoIBqLaIABad4OinbB3e/KCMsaYJLAEUYHr5hreP8G6\nuhpjUpQliAoyA36KS8OESr0kYQnCGJOiqpUgROSIqNFVTxGRa0WkVWJDS45yI7oCtO4KiCUIY0zK\nqW4JYiZQKiLdgcdw93l4LmFRJVHkpkFlCSItA7I7uzGZjDEmhVQ3QYS94btHAX9V1ZuADokLK3ki\nJYh9xdHtEN2sBGGMSTnVTRAlIjIOmAi85k0LJCak5DqgBAFeV1dLEMaY1FLdBHEZcDxwp6p+KyLd\ngGcSF1byHNAGAS5B7N0GhTuSFJUxxjS8at0wyLub27XgbgcKtFDV/0lkYMkSLLsvdYWrqcG1Q2Qm\n/NbYxhjTKFS3F9N7ItJSRHKABcDjInJPYkNLjiyvimlfSYWL5cCG3DDGpJTqVjFlq+qPwAXA06p6\nLPCTxIWVPGVtEBUbqcHaIYwxKaW6CSJNRDoAY9jfSN0kxWyDSG8GzdtbCcIYk1KqmyBuB94CvlHV\neSJyOLAicWElTzBWggDryWSMSTnVbaT+B/CPqPergAsTFVQy7a9iCpX/IOdwWPmvJERkjDHJUd1G\n6s4i8pKIbPYeM0Wkc6KDS4ayKqboNgiAnFzY/T0U72n4oIwxJgmqW8X0BDAL6Og9XvWmNTl+n5Ce\n5otdxQTww+oGj8kYY5Khugminao+oaoh7/Ek0C6BcSVVZsBfvpsr2KiuxpiUU90EsU1ExouI33uM\nB7YlMrBkyqx40yCIuhbCEoQxJjVUN0Fcjuvi+j2wERgNXJqgmJIuM93P3ooliMxWkNXGEoQxJmVU\nK0Go6hpVPU9V26nqIap6Pk20FxPEKUGAK0VYgjDGpIi63FHut/UWRSPjbjsaI0HkHA7bVzd4PMaY\nRk4VwjGOGQe5al0HEYdUOYPIcOA+wA/8TVXvqvB5V2AqrsF7OzBeVdd5n00EbvFmvUNVn6pDrDWS\nGfAf2IsJXIJY8g8IFbkbCRljTEkh/N+FsG6eq2Voc4T36A45R0CHvhDMTnaUtVKXBKGVfSgifuBB\n4HRgHTBPRGZ5I8NG3I0b2+kpETkV+DMwwRsU8FYg31vPfO+7P9Qh3moLBvxs31N84Ac5h7twflgD\n7Y5siFCMMXVVGoJwCQQy63/ZqjDrWljzEQy6FPZsgW3fwMp3oLTIzdPqMPhVwUF5UllpghCRXcRO\nBAJU9WsPBlZ6V10jItOBkUB0gshjf1XVHOBl7/WZwNuqut377tvAcGBaFeusF5nplZQgwLVDWII4\neBXthkAW+OpSw2oavVARfP4MfHgviA+unlv/Z/IfPwBLZsCwW2DoTfunh0th5zpY8U+YfSMsnw29\nRtXvuhtApQlCVVvUYdmdgLVR79cBx1aYZxFuhNj7cLczbSEibeJ8t1PFFYjIJGASwGGHHVaHUMvL\nitdIbaO61g9VWPAUbFwEpSUQDnnPJe5s74hhMPiquq+npBC2fAWbl5V//LgO2vSAc++D3BPrvh7T\nuJTsc4lh7r3w43roOAA2Loa3boaRD9bfer55F97+I/Q8D06+sfxnPj+07gr5l8PcKbDgmaaXIBrA\njcADInIp8AGwHqh2S4+qPgY8BpCfn19plVdNxC1BZLWBjJaWIOpq7r3wzn9BZmtIC4IvAP409xza\nB8tfhxYdoOc5tV/HN3NgxkQo2une+9Oh7VHQ9QRXElz0HDw5AgZOhNO9WMzBrWSfO/GYey/s2ghd\njoORD8Dhw+Cd22HuPZB3PvQ4ve7r2r4K/nEZtDsazn8YJE6TrM8P/X8GH/wv7FgLrbrUfd0NKJEJ\nYj0Q/Wt09qaVUdUNuBIEItIcuFBVd4jIeuCUCt99L4GxlhOM10gt4koRP9iw37U2/ymXHPqMgVGP\nHljNEyqGv58Or1wDHfrV7g9qyQvw0i+gbQ8Yeh8c0sslBX/U7n7itfDen+Hjh2D5G3DWXdDrgvh/\n6KbxUoWvXoM3/wA710LXE92+1e3k/f+fp0x21TyzroVffuyua6pqmfH2haLdMP1i93rss5DRvPJl\nDbgYPvgLLHwOTvl9zbYtyRJZCTsP6CEi3UQkHRiLG8+pjIi0FZFIDH/A9WgCN7T4GSLS2rvF6Rne\ntAaRGfBTHApTGo5RKLFhv2MrDVU9z7LX4LXfQPfT4fyHYrcBpKXD6Kmu2mnmldVbbrSPH4KZV0CX\nwXDZG65Y3+7I8skB3D0+zrgDJs2Blh3hhcvhuTGw47uarc+Ut3YeFEz1Hk/A/CfdScGCp101T33b\nvgqe/Sk8P96V7i+ZBZfNhsOHlj/Ap2W4fW73Jvjnf1S+zAXPwF2HwcMnwT9vcQ3OJYXuM1V4+WpX\ndfnTJ/a3S1amdS50GwoL/w/C4Spnb0wSVoJQ1ZCI/Ap3YPcDU1X1SxG5HShQ1Vm4UsKfRURxVUzX\neN/dLiL/jUsyALdHGqwbQma6O3AVlpTSPKPCT5RzOCx71dWZ+wMNFVLj9uljrn53wMUw9PfugFvR\n6rnuINxpEIx5qvLfrs0RcM4UePFKeP8uOPWW+PNGqMK/boV/3wc9z4UL/gaBYNXf69APrnwHPnsM\n3r0Dnjgbfj3fJarGYNlr8Oq10PZIV5feob97btO98TWyf/shPD0SNE4tsS/g/u+PPrvu6yrZB/+e\nAh/e4/alM/8Eg39+4IlAtE6D4MTr4lc1hUvdPvTRX+Gw48GXBp884t77M6Dr8a6aedksd3JxxKnV\nj3fgJe7E5dv3XRvbQSKhbRCqOhuYXWHaH6NevwC8EOe7U9lfomhQmenuZyksjpEgWndzZ7c711bv\n7KG23rsL9u10RePG3Id62Wvwxu/gkJ7w+bOwaDoMngQnXQ9ZOW6ejYth2jh3JvWzGe7svSp9fwqr\n3oMP7nZVBd1Ojj9vaQnM+jUsmuYaBUfc7ep+q8ufBsf/0h10n/up65UyYHz1v58oe7bCq9e5//9w\nqTsjD3lnsuktoGN/d6Dq2D+5cYIref1jovsNL57hDqioS9yo61H04iSYcQlc+LfaNdgW7YIfN8Lm\nL+Ff/+WqentfCGfcCS07VG8Z8aqaina7EuvXb7j998w/u/2ieI/rwvrNu65da9V70HcsHP+rmsV+\n9DkQbOUazy1BHNwi94SIezU1uKJtohLE7i3w/l/cmdgXL8KI/4W88+p/PeFSQGp/Jrp2njsr6jQI\nJr4KezbDnD+7M675T7l6/iOHu4uIMlrChBf3J43qGPEXWPspzLwKrv43NGt74DxbV8Kbv3c3cxr2\nH3DyTbVvR+hxOrTv43qd9BtXvSRTGqr8rLUu3vidO0mY+CocmufWtXU5bFgIGz539e5PnQsX/wMO\nOy4xMVRH8V6Y/jMX39jn3IlALBNectV4L1zu5u370/jL3PC5q6ba8R38uMElhuJd+z9v0wMmvFzz\ng22kqulvp8Nb/wHnP+gaj6eNdT3cRtxdvgddejO3X0RKG3u3uwN9TfexQBD6jnF/F3u3V/53UPgD\npGVWrwScYJYgYoh5X+qIsgSRwIbqJf9wyWHUo/DRAzBjAhx1tksU2Qf09q2djYtd3e2+HeWv/szx\nrgDt0BcyKunlvH0VTLvI9Tb62fOQngXpuXDBoy4xvHsHvPvf7pGZA5e+Dtk1vMdUejNXz/v4aa7R\n+WczXDLbtQm+fBEWP+8OJOJ3XVYHXVqXX8T90Z90vTuAffUa5I2sfP41H7sDdOuurndU1xPdoz56\nqix7Db6Y6frXH5rnpvnT4NBe7jHgYjjpN65K55lRrrG0JlUe9UUVZv0Kvv/CJaq23ePPG2wJF7/g\nDsYvXgWlxW47om35GubcAUtfcScVbY+Edke5nkgtO0CLjq4Ks8vg2l94Fl3V1OZwV40U2ufi735a\n5d+tyQlORQMmuKrMJf+AY38ee56lr7jeUSKu112HvtC+r/fcp8FrE0S13nqHJlV+fr4WFBTUy7Le\n/WoTlz9ZwCvXnEi/LhV6O6jCnR1cVcbwP9XL+g7wyBB3Yc/P33fVJ5885M7MfWlw2h/hmCtqVoVS\n0fr58MwFLgHkjXQH+20r3c2QSr0ryIPZcMKv4dhfHJgo9mxzPY0Kf4Ar3o5/UPjuUyj4u1tGp4G1\nj/ezx93FRgMmuH7tq94DDbs/nL5jXDVDrHaP2giXwgP5bvuvmhP/TDFUDI+cBMW7XRzffeTO9gGy\nD3MJ45TJ+6+dqYm92+HBY6HFoS6Gytprdm92CWLr1/DTJ+unfr8m5k5x9fan3QpDqjk8W6TEsWqO\na2vKv8xdVPbeXbDwWXcR4/HXuGqcYMvExB0qgkdPdo3NrXNh3PNwyNGJWVe0R092++4v5h742Xef\nuhOO9n1cI/vGxfD9YtewHjFwIpz9/+q1/VNE5qtqfqzPrAQRQ9ArQeyNdbFcpKtronoybfrS7RRn\n/cW99wfc2U7P8+C16+GNm1w/72Zt3YE7owWkN3dd7Vp0hGOuhGZt4i//u0/h2dGu3/+lr7lhACLC\npa5tZesKV7x/9w7XK+ik38AxV7lSQkkhTB/n/qAnvlr5GeNhx7pHXR1zpUsKnz/j4j3pty4xtDuq\n7suuyOd3v/er17l1xqvC+PivrrrnZzPgyDPdb7d5qauvXvNv15Fh10aYOCv29yvz5h+gcDuMn1n1\ngaD5Ie7/4dmfwvMT4ILHoM/o6q9r+yr49FE3jlBWG7e8Zoe45+aHuH2qY//Yw1Ss+Bf86zbXnnDS\n9dVfZ3oWjJvu2iNe+42rHly6KK8AABeNSURBVFzxNqCuoXnIDdA8wfcjS8uA0V4vq6G/r/xvpj4N\nmOBOdjYsLN92tHWlK1lld3L7VHQ8uza5Y8LXb8G8x91+9dMnq9eWV0dWgojh8+9+YNRDH/HEpccw\n7OhDDpzh+Qnw3Sdw7YLKq2Fq45//6UoMNyw/sM5d1VU7LH/DnbkW7XKP4t2ukW3vVtd4efKNrghb\nsQi+ei48OwZatHcHlaqqq9bNhzl3wjfvuIPGkBvcmfLSWW4H7XV+vW56pUr2ubPk9n0Sf61CqAju\n6+euo5j46oGfb/8WHjrO1Utf9H+xl/Hxg65n16WvQ+5J1V/312+5evqTfwenVtEdM1rRLtcRYPVc\nOHdK5dVtqi6JffyQa7D1pbk2jH073VhCe7a4jhgR/nRXLZN7kqtC6zIYdn0Pjw9zpaUr3qrdwSpU\nDC9c5mLo9zN3jUD0CUtTVLgD/t9RrhPE2f/PTdu9Bf7+E/d/eMXbrqo3noKp8PoN0HHggYmklior\nQViCiGH597s4c8oHPHTxQEb0idE74rtPYeqZrrfDiL/UyzoB13B3by9XHTOuFsNObf4K3v5PN/5L\n625w+u2uy6eI64ExbZyrL7/kFZckqmvNx640scYrFp9xJ5xQw14cB5uP/ur6wF/5LnQetH+6qjtb\n/+5juOaz+Em2pNAlmTbdXZKoTlIr3OEST2ZrmPR+zbvalhS6k5eVb3ttIV1de0h2Z8ju4h7rC1zy\n+n6xaxvKv9yV0KJ7AYXDrvpwz2Y3MOV3H7nEs2GhaxvzpblSq/hg0ntun6qtcNiVlmJ1QGiqZl7l\nTgRuXO72p6fOhU1fwMTXoMsxVX9/2WuunaxVFxj/Yt1+f6yKqcbKGqljVTGBqzYZPMk1OPW+sH6q\nUQC+fQ92fw/9xtbu+4cc7RraVr7jemjMmOAOFHnnu4Nd2yPhkpdr/sfY9XhXHfXtB64NoN+42sV3\nMBl0qetiO/ce1wAcsfQVdwA+88+Vl8ACma7E9cbv3O92+NCq1/nPW1ybwtjnancdRiDTfffd/4a1\nn7k+9z9u4IDxNtse5er++17kqnsq8vncmWmzNq778lHD3fSiXe7kaM1cWL/AVc3U8eDk1pVCyQFg\n4ATXlXrpK64qcv18uOiZ6iUHcEPQXPKK6yTy99NdVWT7PgkJ1UoQMWzetY/Bd77DHef3Zvxxcf4A\nina7s71AJvz8w/rpkjbzSlcXe+PXdR8auDTkxqWZ8ydX9dShv+tmWJdeGKnm3TvdEAm//NQl330/\nwoOD3QHtqveq7t5asg/uH+CqTS5/s/JSxMp/ue7AJ10PP7mt/rahtMQl9R1rXftSi/bQ7ZTGd5Fd\nKgmH4a8DXNtCqBCG/w8c94uaL2fzMrfPFO1yJzGVXStUicpKELaXxFBlCQJco/A5U1y9+Id3132l\n+350RcfeF9bPuPH+NNfb6doFbgTLibMsOdTUsb9wPWr+fZ97P+dOV/d+zn3Vu/YhEISTb4C1n7gL\nreLZugJeuALa9YShk+sn9gh/wBvqYYgbNO6IUy05JJvP59ogQoVw3DW1Sw7gSndX/NN1NX/z5oTc\n0c6qmGKo9DqIaD1+4q6qnHuvq8Zp37v2K136itth6rv6JpjdOK4KPhg1a+O6Fc57HI4e4aoUj7mi\nfJtEVQZMcF1B5/zJHZwrliL2bHNtGr401+7UCC6OMg3ghGvh0N7Q48y6LSe7syudFu+pW9f3OOxU\nIoY0v490v6/qBAEw/M/uyspZv4o9sFxpietK98TZrl44nkXT3UVqnWOW9EyynPArQFyXzKy2cOp/\n1uz7aRmuLWJ9gdeVM0rJPnc9wK6Nrttnba6ZMAentAw46qz6Kc1l5SRsGHFLEHEEA77Kq5gisnLc\nFc4bPnfdUyPCYTfs9IPHuj716+fD0+e7vvUV/bDaNfz1H2fDTTc22Z1dY66G3clAVcNEx9L/YtcO\n8d6fvLGJcPvHK7901U+jHql+A6UxDcgSRByZ6f7YYzHF0msUHDXCVSNs+wa+/ic8drIbpygt6M4O\nr1vkenw8O8ZdxxBt8Qz33Pei+t0IUz/OvNNd79D7wtp9Py3dXdew4XP4+k037b0/uWtafnLbQXmn\nMZMaLEHEkRnwx76SOhaR/Ze/PzrUjQhatAsueBx+8aErSrY41PWHP7SXG7v+i5nuu6puFNLcIU3/\nIqGDVWar/deT1Fa/se7alDl3ulFvP/hf1z5x4m/qL05j6pkliDji3lUunpYdXZJocah7vmaeGw4i\nuuEoK8f1X+5yrOu1suBpN8TB9lW1v/bBHBz8AXfdwPdLXNVSt6Fwzr1WpWgaNevFFEdWTaqYIvqO\ncY/KREa0nDHB3cOg7VFuaN+qRg41B78+P4WP7nelxjFP2w2nTKNnCSKOzHR/9RqpayM9y13xOvMK\ndyVlnzH1P6aTaXz8aW6sHX9647ljnTGVsAQRR2bAz469JYlbQVoGjH4S5j/hbqpjUkNVN7g3phGx\nBBFHMJDAEkSEP6383auMMaYRsUbqODJr2khtjDFNjCWIOLLSLUEYY1KbJYg4golspDbGmIOAJYg4\nMgN+ikJhSsNNYzh0Y4ypKUsQcURGdK3xtRDGGNNEWIKIIzO9mkN+G2NME2UJIo5q3TTIGGOaMEsQ\ncURKEFbFZIxJVZYg4oiUIKo9oqsxxjQxliDiqPZtR40xpomyBBFH0BqpjTEpLqEJQkSGi8hyEVkp\nIpNjfH6YiMwRkc9FZLGIjPCm54pIoYgs9B6PJDLOWLIibRBWxWSMSVEJG6xPRPzAg8DpwDpgnojM\nUtWlUbPdAsxQ1YdFJA+YDeR6n32jqv0TFV9VrIrJGJPqElmCGAysVNVVqloMTAcq3hVHgZbe62xg\nQwLjqRFrpDbGpLpEJohOwNqo9+u8adFuA8aLyDpc6eHXUZ9186qe3heRIbFWICKTRKRARAq2bNlS\nj6Hvb4Owbq7GmFSV7EbqccCTqtoZGAE8IyI+YCNwmKoOAH4LPCciLSt+WVUfU9V8Vc1v165dvQZm\nF8oZY1JdIhPEeqBL1PvO3rRoVwAzAFT1YyAItFXVIlXd5k2fD3wDHJnAWA8Q8PsI+MXaIIwxKSuR\nCWIe0ENEuolIOjAWmFVhnu+A0wBEpCcuQWwRkXZeIzcicjjQA1iVwFhjCtpNg4wxKSxhvZhUNSQi\nvwLeAvzAVFX9UkRuBwpUdRZwA/C4iFyPa7C+VFVVRE4GbheREiAM/EJVtycq1ngyG+K2o8YY00gl\n9J7Uqjob1/gcPe2PUa+XAifG+N5MYGYiY6uOQ1sGWbNtb7LDMMaYpEh2I3WjNqhraxau3UFJaTjZ\noRhjTIOzBFGJ/NzWFJaUsnTDj8kOxRhjGpwliErkd80BYN7qBm/+MMaYpLMEUYn22UG65GQyf80P\nyQ7FGGManCWIKuR3zWHe6h9Q1WSHYowxDcoSRBXyc1uzdXcR32233kzGmNRiCaIK+9shrJrJGJNa\nLEFUocchzWkZTKPAGqqNMSnGEkQVfD4hPzeHAmuoNsakGEsQ1TCoa2tWbt7N9j3FyQ7FGGMajCWI\najgm17VDWHdXY0wqsQRRDX07ZxPwCwVrrB3CGJM6LEFUQzDgp0+nbAqsJ5MxJoVYgqim/Nwclqzb\nabcgNcakDEsQ1ZTftTXFpWGWrN+Z7FCMMaZBWIKopkFdWwM2cJ8xJnVYgqimNs0zOLxdM+ZbO4Qx\nJkVYgqiBY7q6C+bCYRu4zxjT9FmCqIFBua3ZWVjCN1t2JzsUY4xJOEsQNRC5YM4G7jPGpAJLEDWQ\n2yaLts3TbeA+Y0xKsARRAyLCoK6tbeA+Y0xKsARRQ8fk5vDd9r1s+nFfskMxxpiEsgRRQ5HrIWzY\nDWNMU2cJooZ6dcwmGPDZwH3GmCbPEkQNpaf56N+lFe8v30JxKJzscIwxJmEsQdTCZSd2Y9XWPUz5\n19fJDsUYYxLGEkQtnNmrPWOP6cLD73/DJ6u2JTscY4xJCEsQtfSf5+SR26YZv31+ITv3liQ7HGOM\nqXcJTRAiMlxElovIShGZHOPzw0Rkjoh8LiKLRWRE1Gd/8L63XETOTGSctdEsI40pF/Vn864ibn55\nCao2PpMxpmlJWIIQET/wIHAWkAeME5G8CrPdAsxQ1QHAWOAh77t53vtewHDgIW95jUq/Lq24/vQj\neX3xRl5csD7Z4RhjTL1KZAliMLBSVVepajEwHRhZYR4FWnqvs4EN3uuRwHRVLVLVb4GV3vIanV8M\nPYLB3XL44ytfsGbbnmSHY4wx9SaRCaITsDbq/TpvWrTbgPEisg6YDfy6Bt9FRCaJSIGIFGzZsqW+\n4q4Rv0+496L++HzCb55fSKjUur4aY5qGZDdSjwOeVNXOwAjgGRGpdkyq+piq5qtqfrt27RIWZFU6\ntcrkT6P68Pl3O7j/3ZVJi8MYY+pTWgKXvR7oEvW+szct2hW4NgZU9WMRCQJtq/ndRuXcfh2Zs3wz\n97+zgi279vGHET1pGQwkOyxjjKm1RJYg5gE9RKSbiKTjGp1nVZjnO+A0ABHpCQSBLd58Y0UkQ0S6\nAT2AzxIYa73406g+/Pzkw3l+3lpOv+d9/rV0U7JDMsaYWktYglDVEPAr4C1gGa630pcicruInOfN\ndgNwlYgsAqYBl6rzJTADWAq8CVyjqqWJirW+BAN+/jCiJy/98kRaZ6Vz5dMFXDvtc7btLkp2aMYY\nU2PSVPrv5+fna0FBQbLDKFMcCvPwe9/wwJwVtAgGuOXsnhx/RBvaNMsgPS3ZTT/GGOOIyHxVzY/5\nmSWIxFr+/S5+N3Mxi9buKJuWnRmgbfN02jbPoG2LDHKy0snODNAqK0DLzACtMgNkZwZI8wvFIaW4\nNExxyD1KvF5SzTLSaJbhp3lGGs0y0miekUYw4EdVKQ0rYYVw2WvFJ+IePvCJ4I96n+bz4fOBXwS/\nTxCRZP1cxpgGVlmCSGQjtQGOat+CF68+gQ9WbGHjjn1s3V3Ell1FbN3tHks3/MiOvcXsLCwh3Ehy\ntQgEfD4y0nykRz/87jngd6/T/ELA7/MegggIAl5+EVwySvN586VJue8ChEqVUNglslA4TKn3I0SW\nm+YX0qNeC249Pm9dIu5Of+GwUuolxMgjrOpi8HkJ0eeSot8HYYVQaZiSUrfeUKlSUuq+4/cJPsFL\noO613/s9Ir9J2W/jd9dvhlVRQFVRBUUpDVMurkjCFlz3aL/Ph99H2bNPxC1HXXzqLROl7LcL+Pf/\nX6T5XHyR3zryf0e5KRUpoVIXUziMF1sYVbd+iWy3uO0WERTF+1cWX2Rdsb6T5q/4W/nJCPjwiVDi\nneQUe799San7Pw/4hTSfj0Caj4C3v/j97v+1pNT9bpF5Q+Fw2QlQOOw9qzspSvMJWel+stLTyAz4\nyUz3e/umoKoUhcLsKykte3YnXPu3IbLPikT+j7yHCH6/e453/iRIkzvRsgTRAPw+YdhRh1Q6Tzis\n7C4OsXNvCTsLS9ixt4RSVe+gLKT7/WUHalVlT1Epu4tC7CkKsac4xO6iEIXFpd4BMOrA5v3hlh2w\ndP+BqjTs/tgrHlhLw0pJeH+ppTgULl+KCSsl3us9RaGyP/TIARIoO7CF1SWAksgBIRQ5OIQRL3mk\neX+EAb8Pv09Q9h+8I/PWpqArQrW+5/ftT2KR70R+o+jfxxycIgf5hh6e3xeVZAJe8is7WfILaX5f\n1AnF/hOCSOIrDUcSufsbCkf2wajELLgk3qdTNk9dXv/XEluCaCR8PqFlMEDLYKBc/17jRM4gI2fn\nkYO4Ahqm0qqyyFl8OOqs2Sdu/uiz8Mqo7q/qKwqVf47+Q41+7feq8CJnoJGSjHrbE0meZQeAsqrA\n6NKRW3+odP/6S6LOviO/h4vRi7WKbUkrK0ntfwjRJQR3Nr6/FCblSgtu+ygr6UROOtT7Tii8//cp\nKglTFHJn7GHvhCcQVQoN+H34BErC6p0U7N+2UKl6Jw6utOVKrF7JK6qEEzkQi0BJqVJYXMre4lL2\nFofYV+Jel4aVjICfYMCVaIIBH8E0PwGvPTByoA5HPVf8/4mcPMUTXa0b/f8b2XdDpVp++8LuJKls\n34GobRKvdCnl9p/o/+dIrIrSuXVWlftwbViCMAcF94dSu+G4fD7BF7fKpXpExFWVpPlpUaclGXPw\nsO40xhhjYrIEYYwxJiZLEMYYY2KyBGGMMSYmSxDGGGNisgRhjDEmJksQxhhjYrIEYYwxJqYmM1if\niGwB1lQxW1tgawOE0xil6rbbdqcW2+6a66qqMW/J2WQSRHWISEG8UQubulTddtvu1GLbXb+siskY\nY0xMliCMMcbElGoJ4rFkB5BEqbrttt2pxba7HqVUG4QxxpjqS7UShDHGmGqyBGGMMSamlEkQIjJc\nRJaLyEoRmZzseBJFRKaKyGYR+SJqWo6IvC0iK7zn1smMMRFEpIuIzBGRpSLypYhc501v0tsuIkER\n+UxEFnnb/V/e9G4i8qm3vz8vIunJjjURRMQvIp+LyGve+1TZ7tUiskREFopIgTet3vf1lEgQIuIH\nHgTOAvKAcSKSl9yoEuZJYHiFaZOBd1S1B/CO976pCQE3qGoecBxwjfd/3NS3vQg4VVX7Af2B4SJy\nHPA/wL2q2h34AbgiiTEm0nXAsqj3qbLdAMNUtX/U9Q/1vq+nRIIABgMrVXWVqhYD04GRSY4pIVT1\nA2B7hckjgae8108B5zdoUA1AVTeq6gLv9S7cQaMTTXzb1dntvQ14DwVOBV7wpje57QYQkc7A2cDf\nvPdCCmx3Jep9X0+VBNEJWBv1fp03LVUcqqobvdffA4cmM5hEE5FcYADwKSmw7V41y0JgM/A28A2w\nQ1VD3ixNdX+fAvwOCHvv25Aa2w3uJOCfIjJfRCZ50+p9X0+r6wLMwUVVVUSabN9mEWkOzAR+o6o/\nupNKp6luu6qWAv1FpBXwEnB0kkNKOBE5B9isqvNF5JRkx5MEJ6nqehE5BHhbRL6K/rC+9vVUKUGs\nB7pEve/sTUsVm0SkA4D3vDnJ8SSEiARwyeFZVX3Rm5wS2w6gqjuAOcDxQCsRiZwANsX9/UTgPBFZ\njasyPhW4j6a/3QCo6nrveTPupGAwCdjXUyVBzAN6eD0c0oGxwKwkx9SQZgETvdcTgVeSGEtCePXP\nfweWqeo9UR816W0XkXZeyQERyQROx7W/zAFGe7M1ue1W1T+oamdVzcX9Pb+rqhfTxLcbQESaiUiL\nyGvgDOALErCvp8yV1CIyAldn6QemquqdSQ4pIURkGnAKbvjfTcCtwMvADOAw3JDoY1S1YkP2QU1E\nTgI+BJawv076Zlw7RJPddhHpi2uQ9ONO+Gao6u0icjjuzDoH+BwYr6pFyYs0cbwqphtV9ZxU2G5v\nG1/y3qYBz6nqnSLShnre11MmQRhjjKmZVKliMsYYU0OWIIwxxsRkCcIYY0xMliCMMcbEZAnCGGNM\nTJYgjKmCiJR6o2ZGHvU24J+I5EaPvGtMY2JDbRhTtUJV7Z/sIIxpaFaCMKaWvDH5/+KNy/+ZiHT3\npueKyLsislhE3hGRw7zph4rIS969GxaJyAneovwi8rh3P4d/eldEIyLXeve3WCwi05O0mSaFWYIw\npmqZFaqYLor6bKeq9gEewF2pD/BX4ClV7Qs8C9zvTb8feN+7d8NA4Etveg/gQVXtBewALvSmTwYG\neMv5RaI2zph47EpqY6ogIrtVtXmM6atxN+tZ5Q0U+L2qthGRrUAHVS3xpm9U1bYisgXoHD30gzc0\n+dveTV4Qkd8DAVW9Q0TeBHbjhkp5Oeq+D8Y0CCtBGFM3Gud1TUSPFVTK/rbBs3F3QhwIzIsapdSY\nBmEJwpi6uSjq+WPv9Ue4EUYBLsYNIgjuNpBXQ9lNfrLjLVREfEAXVZ0D/B7IBg4oxRiTSHZGYkzV\nMr07tkW8qaqRrq6tRWQxrhQwzpv2a+AJEbkJ2AJc5k2/DnhMRK7AlRSuBjYSmx/4Py+JCHC/d78H\nYxqMtUEYU0teG0S+qm5NdizGJIJVMRljjInJShDGGGNishKEMcaYmCxBGGOMickShDHGmJgsQRhj\njInJEoQxxpiY/j+Qu04h0+TktAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jccWyDYQ9YnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9bfb03b1-0d5e-47eb-eb1a-452c312872ec"
      },
      "source": [
        "training_val_error_plotter(train_mae, val_mae)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3wUdfrA8c+zqZDQiVIlFJVeI2IB\nQTwFVFTEgmLBwh0/T7079eQ8Tz3LWc5Dz94OK4IoIqgoKqKgqBiQDgoiQgAhoPSWZL+/P57dZBNS\nNmWzSeZ5v16w2dnZme/szs7z7SPOOYwxxniXL9oJMMYYE10WCIwxxuMsEBhjjMdZIDDGGI+zQGCM\nMR4XG+0ElFbjxo1dampqtJNhjDHVyoIFC7Y551IKe63aBYLU1FTS09OjnQxjjKlWROTnol6zqiFj\njPE4CwTGGONxFgiMMcbjql0bgTGmcmRlZZGRkcGBAweinRRTComJibRo0YK4uLiw32OBwBhTqIyM\nDOrUqUNqaioiEu3kmDA459i+fTsZGRm0bt067PdZ1ZAxplAHDhygUaNGFgSqERGhUaNGpS7FWSAw\nxhTJgkD1U5bvzDuBYMsKmHUP7N0W7ZQYY0yV4p1AsH01zH0Ydm+OdkqMMSXYvn073bt3p3v37jRp\n0oTmzZvnPj906FBY2xg1ahTff/99ses8+eSTTJgwoSKSzMknn8yiRYsqZFuVzTuNxfHJ+nhob3TT\nYYwpUaNGjXIvqnfddRfJycncfPPN+dZxzuGcw+crPD/74osvlrif6667rvyJrQG8UyLIDQR7opsO\nY0yZrVmzho4dO3LppZfSqVMnNm/ezOjRo0lLS6NTp07cfffduesGc+jZ2dnUr1+fsWPH0q1bN044\n4QS2bt0KwO23386jjz6au/7YsWPp3bs3xx57LPPmzQNg7969nH/++XTs2JHhw4eTlpYWds5///79\nXHHFFXTp0oWePXsyZ84cAJYuXcpxxx1H9+7d6dq1K2vXrmX37t0MHjyYbt260blzZ956662K/OiK\n5aESQZI+HrRAYExp/fPd5azYtKtCt9mxWV3uPLtTqd+3atUqXnnlFdLS0gB44IEHaNiwIdnZ2QwY\nMIDhw4fTsWPHfO/ZuXMnp5xyCg888AB/+ctfGD9+PGPHjj1s28455s+fz/Tp07n77rv58MMPefzx\nx2nSpAlTpkxh8eLF9OzZM+y0PvbYYyQkJLB06VKWL1/OkCFDWL16NU899RQ333wzF110EQcPHsQ5\nx7Rp00hNTeWDDz7ITXNl8U6JIMGqhoypCdq2bZsbBAAmTpxIz5496dmzJytXrmTFihWHvadWrVoM\nHjwYgF69erFu3bpCtz1s2LDD1vniiy+4+OKLAejWrRudOoUfvL744gtGjhwJQKdOnWjWrBlr1qzh\nxBNP5N577+Whhx5iw4YNJCYm0rVrVz788EPGjh3Ll19+Sb169cLeT3l5qERgVUPGlFVZcu6RkpSU\nlPv36tWr+e9//8v8+fOpX78+I0eOLLQPfXx8fO7fMTExZGdnF7rthISEEtepCJdddhknnHAC77//\nPoMGDWL8+PH069eP9PR0ZsyYwdixYxk8eDC33XZbxNIQyjslAgsExtQ4u3btok6dOtStW5fNmzcz\nc+bMCt/HSSedxOTJkwGt2y+sxFGUvn375vZKWrlyJZs3b6Zdu3asXbuWdu3aceONN3LWWWexZMkS\nNm7cSHJyMpdddhk33XQTCxcurPBjKYp3SgSxCSAxVjVkTA3Ss2dPOnbsSPv27WnVqhUnnXRShe/j\n+uuv5/LLL6djx465/4qqtjnjjDNy5/jp27cv48eP5/e//z1dunQhLi6OV155hfj4eF5//XUmTpxI\nXFwczZo146677mLevHmMHTsWn89HfHw8zzzzTIUfS1HEOVdpO6sIaWlprsw3prn/KOh2MQx5qGIT\nZUwNtHLlSjp06BDtZERddnY22dnZJCYmsnr1ak4//XRWr15NbGzVzUcX9t2JyALnXFph61fdI4mE\nhGQrERhjSmXPnj0MHDiQ7OxsnHM8++yzVToIlEXNOpqSxCfBod3RToUxphqpX78+CxYsiHYyIso7\njcWgDcZWIjDGmHw8FgiSLBAYY0wBHgsEyTay2BhjCvBWIEhItnEExhhTgLcCQXySBQJjqoEBAwYc\nNjjs0UcfZcyYMcW+LzlZB45u2rSJ4cOHF7pO//79KakL+qOPPsq+fftynw8ZMoQdO3aEk/Ri3XXX\nXTz88MPl3k5Fi1ggEJHxIrJVRJYVs05/EVkkIstF5PNIpSWXNRYbUy2MGDGCSZMm5Vs2adIkRowY\nEdb7mzVrVq7ZOwsGghkzZlC/fv0yb6+qi2SJ4CVgUFEvikh94ClgqHOuE3BBBNOi4pMhax/4cyK+\nK2NM2Q0fPpz3338/9yY069atY9OmTfTt2ze3X3/Pnj3p0qUL06ZNO+z969ato3PnzoBOBX3xxRfT\noUMHzjvvPPbv35+73pgxY3KnsL7zzjsBnTF006ZNDBgwgAEDBgCQmprKtm16d8Nx48bRuXNnOnfu\nnDuF9bp16+jQoQPXXnstnTp14vTTT8+3n5IUts29e/dy5pln5k5L/cYbbwAwduxYOnbsSNeuXQ+7\nR0NZRWwcgXNujoikFrPKJcDbzrn1gfW3RiotuYJTUR/aC4l1I747Y2qMD8bCL0srdptNusDgBwp9\nqWHDhvTu3ZsPPviAc845h0mTJnHhhRciIiQmJjJ16lTq1q3Ltm3b6NOnD0OHDi3yXr1PP/00tWvX\nZuXKlSxZsiTfNNL33XcfDRs2JCcnh4EDB7JkyRJuuOEGxo0bx+zZs2ncuHG+bS1YsIAXX3yRb775\nBuccxx9/PKeccgoNGjRg9erVTJw4keeff54LL7yQKVOm5M48Wpyitrl27VqaNWvG+++/D+i01Nu3\nb2fq1KmsWrUKEamQ6iqIbhvBMUADEflMRBaIyOVFrSgio0UkXUTSMzMzy75Hm4ramGojtHootFrI\nOcdtt91G165dOe2009i4cSNbtmwpcjtz5szJvSB37dqVrl275r42efJkevbsSY8ePVi+fHmJE8p9\n8cUXnHfeeSQlJZGcnMywYcOYO3cuAK1bt6Z79+5A8VNdh7vNLl268PHHH3Prrbcyd+5c6tWrR716\n9UhMTOTqq6/m7bffpnbt2mHtoyTRHFkcC/QCBgK1gK9E5Gvn3A8FV3TOPQc8BzrXUJn3aLerNKZs\nisi5R9I555zDn//8ZxYuXMi+ffvo1asXABMmTCAzM5MFCxYQFxdHampqoVNPl+Snn37i4Ycf5ttv\nv6VBgwZceeWVZdpOUHAKa9BprEtTNVSYY445hoULFzJjxgxuv/12Bg4cyB133MH8+fOZNWsWb731\nFk888QSffvppufYD0S0RZAAznXN7nXPbgDlAt4juMTcQ2DQTxlR1ycnJDBgwgKuuuipfI/HOnTs5\n4ogjiIuLY/bs2fz888/Fbqdfv368/vrrACxbtowlS5YAOoV1UlIS9erVY8uWLbl3BgOoU6cOu3cf\nfp3o27cv77zzDvv27WPv3r1MnTqVvn37lus4i9rmpk2bqF27NiNHjuSWW25h4cKF7Nmzh507dzJk\nyBAeeeQRFi9eXK59B0WzRDANeEJEYoF44HjgkYjuMbSNwBhT5Y0YMYLzzjsvXw+iSy+9lLPPPpsu\nXbqQlpZG+/bti93GmDFjGDVqFB06dKBDhw65JYtu3brRo0cP2rdvT8uWLfNNYT169GgGDRpEs2bN\nmD17du7ynj17cuWVV9K7d28ArrnmGnr06BF2NRDAvffem9sgDJCRkVHoNmfOnMktt9yCz+cjLi6O\np59+mt27d3POOedw4MABnHOMGzcu7P0WJ2LTUIvIRKA/0BjYAtwJxAE4554JrHMLMArwAy845x4t\ndGMhyjUNdcYCeOFUGPEGHFtkhyZjDDYNdXVWZaahds6V2OHXOfdv4N+RSsNhEuwuZcYYU5D3RhaD\nVQ0ZY0wIjwYCKxEYE47qdgdDU7bvzGOBwLqPGhOuxMREtm/fbsGgGnHOsX37dhITE0v1Pm/doSwm\nDmIS4KB1HzWmJC1atCAjI4NyDeI0lS4xMZEWLVqU6j3eCgRg9y02JkxxcXG0bt062skwlcBbVUNg\ndykzxpgCPBgI7OY0xhgTygKBMcZ4nAcDQZLdt9gYY0J4LxBYY7ExxuTjvUBgt6s0xph8PBgIkmwa\namOMCeHBQGAlAmOMCeXNQJBzCLIPRTslxhhTJXgvENhU1MYYk4/3AoFNRW2MMfl4OBBYicAYY8CT\ngaCOPlqJwBhjAE8GgkCJwKaiNsYYwIuBIMFuTmOMMaG8FwjsLmXGGJOPBwNBsLHYqoaMMQY8GQis\nRGCMMaG8FwjiauujBQJjjAG8GAh8PoizexIYY0yQ9wIBBO5JYIHAGGPAq4EgPskCgTHGBHg0ENhU\n1MYYE2SBwBhjPM6jgSDJppgwxpgAbwYCu4G9Mcbk8mYgsMZiY4zJ5dFAUMdKBMYYExCxQCAi40Vk\nq4gsK2G940QkW0SGRyothwmWCJyrtF0aY0xVFckSwUvAoOJWEJEY4EHgowim43DxSeD8kLW/Undr\njDFVUcQCgXNuDvBrCatdD0wBtkYqHYVKsLuUGWNMUNTaCESkOXAe8HQY644WkXQRSc/MzCz/zm0q\namOMyRXNxuJHgVudc/6SVnTOPeecS3POpaWkpJR/zzYVtTHG5IqN4r7TgEkiAtAYGCIi2c65dyK+\n59wSgQUCY4yJWiBwzrUO/i0iLwHvVUoQgLwSgU1FbYwxkQsEIjIR6A80FpEM4E4gDsA590yk9huW\n3BvYWyAwxpiIBQLn3IhSrHtlpNJRqNyqIQsExhjj0ZHF1lhsjDFBHg8EViIwxhhvBoLYBJAYayw2\nxhi8GghEbCpqY4wJ8GYggMBdyqxEYIwxHg4Edk8CY4wBTwcCqxoyxhjwdCBIssZiY4zBy4Egwe5S\nZowx4OVAYG0ExhgDWCCIdiqMMSbqPBwIrLHYGGPA64Egax/4c6KdEmOMiSrvBoIEm3jOGGPAy4HA\n7lJmjDGApwOBzUBqjDFggcACgTHG8zwcCAJVQza62Bjjcd4NBNZYbIwxgJcDgVUNGWMM4OlAYDew\nN8YY8HQgsKohY4wBTwcCayw2xhjwciCIiYOYBKsaMsZ4XliBQETaikhC4O/+InKDiNSPbNIqgd3A\n3hhjwi4RTAFyRKQd8BzQEng9YqmqLDYVtTHGhB0I/M65bOA84HHn3C1A08glq5LE213KjDEm3ECQ\nJSIjgCuA9wLL4iKTpEoUnwQHd0c7FcYYE1XhBoJRwAnAfc65n0SkNfBq5JJVSeKTrERgjPG82HBW\ncs6tAG4AEJEGQB3n3IORTFilSEiG3b9EOxXGGBNV4fYa+kxE6opIQ2Ah8LyIjIts0ipBfLI1Fhtj\nPC/cqqF6zrldwDDgFefc8cBpkUtWJbFAYIwxYQeCWBFpClxIXmNx9RefZCOLjfGqXZvgu9fA7492\nSqIu3EBwNzAT+NE5962ItAFWF/cGERkvIltFZFkRr18qIktEZKmIzBORbqVLegWITwZ/FmQfqvRd\nV5qDe2DWPbBxQbRTYkzVkX0IJl0C066DGTeBc9FOUVSFFQicc28657o658YEnq91zp1fwtteAgYV\n8/pPwCnOuS7APehAtcqV4IGpqL96AuY+DM+fChMvgS3Lo50iY6Jv9n2w6Tto9ztIHw8f3e7pYBBu\nY3ELEZkayOFvFZEpItKiuPc45+YAvxbz+jzn3G+Bp18DxW4vImr6VNT7foWvnoRjBsGAv8O6ufD0\nSTDlGtj+Y7RTZ0x0/DQHvvwv9LwCLn0Teo/WDNPsf0U7ZVETbtXQi8B0oFng37uBZRXlauCDCtxe\neGr6VNTzHtcBcwPvhFP+CjcuhpP/BKvehyeOg+nXa7Awxiv2/Qpv/x4atYNB94MIDHoQeoyEOQ/B\nF49EO4VREW4gSHHOveicyw78ewlIqYgEiMgANBDcWsw6o0UkXUTSMzMzK2K3KhgIamKD8Z5M+OYZ\n6Hw+HNlRl9VuCKfdBTcsgt7XwqLX4eM7opnKyHEOFr9hgc7kcU4zP3szYfj/8moEfD44+zHoPBw+\nuQu+eTaqyYyGcAPBdhEZKSIxgX8jge3l3bmIdAVeAM5xzhW5Pefcc865NOdcWkpKhcQfVZOrhr58\nFLIPQP+xh79W50gY/CB0GwHLpsCBneFtc9MiWDypYtMZKeu/hqmjYdbd0U5Jfh6uh466hS/Dqvfg\ntDuhaYG+Kb4YOO8ZaH8WfPBXWFj9J04ojXADwVVo19FfgM3AcODK8uxYRI4C3gYuc879UJ5tlVlN\nvYH9rk3w7Qt6oW98dNHrpY2CrH2wZHLJ23QOpv0R3vk/OLCr4tIaKYsn6uN3r8HOjOimJcjvh1eG\nwptXQk52tFNTdr/9DM8PhLWfRzsl4cv8AT4YC20GQJ/rCl8nJg6Gj4d2p2nJYcKFsGJ6ze5VGBBu\nr6GfnXNDnXMpzrkjnHPnAsX2GhKRicBXwLEikiEiV4vIH0TkD4FV7gAaAU+JyCIRSS/PgZRJTb2B\n/dz/gD9b2wWK06yn5ozSXyw5p7p2NmxZCi4Hfp5XcWmNhKwDsPwdaH2KPv/i0eimJ2jFVG2oXD61\n+nZZdA6m/xE2puvjoX3hvy9a/fWzD8KUqyG+tub6fcVc9mIT4MJXod/N8MsSmHwZjOsAM/8OW1dV\nXporWXnuUPaX4l50zo1wzjV1zsU551o45/7nnHvGOfdM4PVrnHMNnHPdA//SypGWsqmJgWDHeljw\nMvS4DBqkFr+uCPQaBVuXQ8a3xa/75WOQfCTEJsJPpcgJbv9Rf4iV6YcP4OBOOPnP0P0SrRLYtaly\n01BQThZ8eh8c0RFO+hMseEkDdnWz4EUNZj1G6rk256GS35OTDa+eB+NPh6z9kU9jqO0/agnslyUw\n9Amo06Tk98TXhlNvhz8tg0smQ6sTtL3tqePhhdNqZEAoTyCQCktFtOS2EdSgqqHPH9ILfL+bw1u/\ny3C9L0P6+KLX2bxESwR9xsBRfWDtZ+Fte8tyeLwX/PtoeOc6WDOr7FUie7bCT3PDW3fxG1CnKbTu\nB33/As6vgSyaFk2AX3+EU/+hDfZdL4JP76k+bS6gF/6P/qGf69AnoPtI7Zm2ZUXx7/v0bj1/Mr6F\nGbdUTlp3ZsD0G7R33I+z4bR/QvshpdtGTCwccwZc9Br8ZRWcfh9s+6HqtTtVgPIEgmpYri0grrY+\n1pReQ9t/1J5AaVdBvTCHZSTUga4XaHVFUT1s5j2mpadeo6BNf9i6AnZvKXnbK6ZrUDp2MKycDq8N\ng/8cC+/fBD9/FX7VSPZBfe/LZ5c8IG7vNljzMXS5QBsAG6RCt4s1JxtOmiMhaz989iC06K2fhYhe\nSFv305Gt4QbWIOd0pPich+GXQgfuV7xgjxvQtIvA7+6GhLrw3p+LrvZZNUP77KddBX1vhu9ejWxD\n7J6t2hbwWA9tJzruGrhxkXabLo/kFDjxj5B2tZY4d26smPRWEcUGAhHZLSK7Cvm3Gx1PUL35fIGJ\n52pIieDzByEmHk4uttbucGlXaQ+jwnKnO9bDsreh15VQq35evXs41UOr3oeWx8OwZ+Hm1ZqzSj1Z\nG3BfHARTfx9eMJh1N/yyVOtvSxr0s2yKto90G5G3rO9NWjUzL0qlgm9fgN2bYOAdegEFiI3Xz6Px\nsfDGZeFd0Pdu0wGCT5+oI8U/vQeeOQkmXaqltkha+LIGrN/dDQ1a6bKkRnD6PbDha73AF/TbOnjn\nD9oOdcb9MOA2PX9m3AybF1ds+vw5Gmz/2w3mP6clrusXwJCHwqsOClevK/ScXfhKxW2zCig2EDjn\n6jjn6hbyr45zLqx7GVR58UlwqJrfpezQXlj6lvb+6X2tdg8tjSZdoHma5poLXpi/flovXn3G6POm\n3SCxfsk9Rn77WRuXjw0Ux+MSocPZcOHLcMsaDVZL3tDgVZw1n+ioz96j9YK+6r3i501aPEmPJzh2\nAqBhG+h6oVZ/7anAcSjhOLAL5o6DtqdC6775X0uspyNb45NhwgWay8zJ1kGAe7fBjg2wbQ18/6EG\ni/+0h5m3QVwtOOsRuHEJ9Pur1tk/21enEKnoCyxoOmberiWYXqPyv9b9Umh1ko5HCf1ssw7A5Cu0\n3uCCl/X798Vor5xaDWHy5bB/R8Wkb/8OeP0i+OxfcPTpcN18OOcJqH9UxWw/VINU7VW08OXq3fOr\ngPJUDdUM1fUuZTvWw/zn4bXz4cHW2iuibnNtiCyLtKu0/vPnL/OW7f9NG547n59X1eSL0QvC2s+K\nz81/Hxgo3v7Mw19LqKO5426XwGf3F919dU8mTB2jDay/uxuO/4NeRD69r/D1M3+ATQuh68WHv9b3\nJi31fPVE0WmOhK+egP2/attAYeo1h5FvaYeFRzrCPY3g/hbw77bwaGd4ohdMvEi/l96jYcxXcO2n\n+n01aAWn/h3+tAROGQvrvoBn+8HrF8PWlRWTfufg3Ru0nWXo44f3uBHRoHRor87XEzTzNti8CM57\nGhq2zlue1FgzAzszYOofyt+TaNtqbcBdOxvOHKfbbtyufNssSdpVsHsz/PBh+bZThXqN1YxcfXlE\nu2rot3UgPr2I+2IKX8c5+HUtbFyoF7q1n2tPH9Dc7nHXwLGD4KgTtC90WXQ6Dz78m3YlTT1Zl6WP\nh6y9cOIN+ddt01/r/Lf/WPSP7vv3tdqjUdvCXxeBs/+rAW3adZp7O6pP/mOe9n862O3yaZoLjqul\nPYE+/od2YW11Yv5tLpmkn2WXCw7fX+OjNaDNf16PJ6lROJ9K+QSrcjoMheY9i17vyE5wxbta2olJ\n0NxzbKJWhcUm6ojw1H5anVSYWg1gwN/ghP/TUbFfPQHPnAwnXq8lhvjaZT+G716FHz+FIQ8X3Qst\n5Vg46Uad3LD7JVpPn/4/3X9hGYGWvbXh9cNbdeBj31JWZQat/hjeulobdS+fDqknlW07pXX06fp7\nTR8PHc4q2zaWvKltZSder//iEis2jaVkgSA+OXqNxTs3wuNpOhW2L04vhg1bQ4PW+qPbt10v/Ju+\nyxv9G1sLWqTB6ffCMYMrLvcTXxu6j9CTe+82zbV/8yy0HQhNOudft01/fVw7u/D97/8N1n0JJ91w\n+GuhYuPholc1RzfpErjmEw1soPW8qz/SC1BoNc9x1+iFbtY9MGpGXp27368li7anFl011vdmrUL7\n+ikYWEQOvSLN/Y8O2Dv19pLXbdZd/5VHYj0dO5J2tQbLLx7R9p0zx8HRxdxHyjmddmFvpp5ze7fl\nPX79FKT21W0Wp9/NsOytwBQO2zRTMvDOotc//vew4Rtt52iRpqXMcDmn7T2f3AVHdIIRr0emGqgo\nMbE6Yd1n/4Jff8pf4gnHgV0w82/a73L2vbDoNRj0gE4OGTyfK5kFgoRkzcFEw9I3NQicfq/+eH77\nSUsIG77VfvC+WM0tdhqmOcpmPSGlvZ6IkdBrlPaXXjRBc5l7tsCwQmYHb9gG6rXUBuPe1x7++uqP\ndeDZsYXkBguq3VDryV8YqPW8V3+kff4/+of+MI67Jv/68bWh3y3a4Pjjp9BuoC5fPw92bij+4nNE\ne+h0rga4E/+oxxgpOzYERndfojnmypTUCM59ShvM3/szTDhfz6FB92vDafYh7Vf/8zydimPD13rh\nL0zDtoVXCRUUVwvO/I9WVdZupG0BxZVORXS7W5ZpVVaHszSNbU8tuuSTtR/Wf6XVlSvegY7n6nEG\nu4FXpp6XafvWwpe1O3BpzH1Yg+61szWD98FfYeLFOiX24AeLLkVHkLgqVE8VjrS0NJeeXoGDkN+8\nUnukXB+FG7c8fZL+gK75JP9y5zRXHVe78ouM4wfDnl80CMUmwu/nFJ5LmXYdrHwX/vrT4VVak6/Q\nH+xfVpV8AQla9wW8cq4O3tmTqfXqY+ZpnXJB2Qd1fEJSitaXi2h6lr+jvZOKqwrZslx73fT7q9av\nl9eBnVq1mHNIL7A5hyDnoFYJrXwXrl8I9VuWfz9llX1QR1bP/Y9+n006axVjdmBgV8M2mntv2k0/\nz6TGULuxPtZqWPpMx8JXtbE+3NLNbz/DnH/rZ3Vgh5Zq2p8NnYdpFeUvy7TkufYz2DBfP9uYeC35\n9L05ajloQHtrrf8a/rKy6OBV0PYf4cnjtVfTuU/qsuxDMP9Z7fWUcxBOuE7bfCr4ty8iC4oauGsl\ngmg1Fm9Zrrmhwf8+/DURzSlHQ9ooeDuQyz//f0X/0NoM0G6gmxdB8155y7MPak+fzueHHwRAf/RD\nH4N3Ar2TRr5deBAArTs/5Vad4uD7GZqLXD4NOp5Tcn34kZ20PeSrJ+G4q8vWtdCfow2F85/Xi1RR\n+lwX3SAA+ln1v1UHDs78uwb5tFHaHtOyT+l7mJWk52WlW79BK+3hc+Y4vdgvmwIrpml1ifi0kRrg\nyC5a+mwzQDML0SgFFJQ2Stt1Vr2r53s4Prpdv5OBIbP+xsZrO0GXC7S664tHtFZgxOsaGCuBBYL4\nOtEJBEsmg8Rozqcq6TAUat2qbScdzy16vWCd7trP8geCn+ZqD5jCGglL0v2SwBQELq/KpyjdRugP\n5tP7dL6bQ7s1lxWOgXfAyvfgswfg7FLMQ7QnU6sCFryk1VB1m2vJom4zzaXGJuhjTLxeqFpVUuNl\nOBq1hUuq8Cjm2Hg45nT9l3VAMxMbvoam3XXsQXIFzjpcUdqcCvVbaQeLcALBmlmacTntn4UH4DpN\ndC6ktgN1/MWLZ8LIKRUfrAthgSA+SS9czlVeMdPv10bLdgOLzvVGS1wiXDxBqxGKqxZIPgKO7KyB\noO9Necu/fx/ikvIGnpXWcSU0SgbFxOoApSlXw4djoW4LbdQMR8M2up/5z+v4iJLq8HdmaE5t+Tva\nptP6FK1vP2Zw5NprvCwuUdsMytojp7L4fFoq+OQu7bqcckzR6+ZkaZfaBq3zxuQUpesF2n41+TKd\nn+myqXmdKCLExhEkJGvxs7yTYe3/Tedd+WCsVh0UZ/082JURfg62srU6sfjujkGtT4H13+R9dn6/\njh9od2rltG10GqZjDPZt0xDHXwAAABLsSURBVB9Paaqi+v1VMwGf3FX8eof26XTEq2Zo8LjuW7hi\nug6OsyBguo/UHn8LSrhhY/p4yFwFZ9ynJceSHH2adik+sBP+d0bER45bICjvDKRbV8K7f4JxHbX+\n75untddNcZa8obnmYweXbZ9VRZv+2ri1/mt9vvk7HWgTTm+hiuDz6UCz+GT9QZZGUiMdk/D9DO3q\nWhjn4L0/6dxKF72iPTqKy/UZ70lOgY5D9TdfVGZy73aYfZ/+Xo4txcR3LdLgqpna++qlM7VDRYRY\nICjLXcr8OZpDfHkoPNVHJ3rrPEx72LQ8XufGKermLVkHtGGzw1lVo8GrPFqdqL2LgpOmrXpf2z2O\nOaPy0nD07+BvGWUbT9FnjNbzf/yPwkd5fvuCBu0Bt+m0AsYUJu0qzbl//ZR2Ay/os3/pWKUz7i99\n9XPKsRoM6jSBV4fpbywCrGxblhvYvzVKezbUba791ntekTdSddD9OiHY3P/A7/55+HtXf6RjBLpe\nWP60R1tCss6omRsIZmhXxMru8VTWtp24WjDg7zqCefnU/A3367/Rtoejz9BuisYUpdVJ2v121t36\nLykFjugAKR10CpH08ToeJnRgZGnUbwmjPoTXL9CxPRFggSCYKw93dPHqTzQI9L0J+t92eD1x8146\niOjrp3TGzoKjDpdO1hOldf/yprxqaNNf5wvauAAyV8IZJcwOWtV0u1i/q1n/1J5OsQk6wPDNK3R+\npWHPlq7twXiPCFw5AzLma1Xx1hV685rvXtMpWmo1hP5/K98+khrlVRNFgAWChDr6GE6JIPuQ5hIb\ntdMBH0U1Fg68Q0c+fnyHTqEQtP83+GGmDtevKQ2NbU7Rou+Ht+nz0tSBVgW+GC25vXZ+IOd2Lbw5\nSr+raz6J7OhjU3MkJOt4lran5i3z+7WbcUx8xZSSIxQEwAJBSBtBGFNRz38Wtq+GS94sfiRh3aY6\nzfLse7WBJziJ24rpOvK0ayGTolVXzXtp9dqGr7UHT2nnXakK2g7Uks3nDwZmYP0Czn1GR8gaU1Y+\nX969G6o4K/PWDtTt/zCz+Glh92zV20AeHRj0UpIT/6jz8XwY0p10yWSdu6VZGF0zq4uYuLxAV5ZB\nZFVB8G5b+3fk1ed2H1Hy+4ypISwQ1GmijYGLJ8Kn9xa93qx/avewM+4Pb7txtbTK4Zel2rVsxwbN\naXa9KLrzo0RCsDhcXQMBaGPfCddpoK9u7RzGlJNVDYFOE7w3U2cFTEqBPn/I//rGBdrwc+L1peum\n2GmYznQ56x6dXAt0zpeapteV2kuiWY9op6R8zijihjfG1HBWIgDNoZ85DtqfpTfLWPpW3mt+P3xw\nKyQdoaNRS7vdQffD3q0aZFocF5UpZiMuNqF088kbY6oUCwRBMbE622ark/UWemtm6fKlkyHjW51z\nPLFu6bcb7E4K0KUGjB0wxtQ4FghCxSXq1K8p7fVm4Ws/1y6gzXvpbJdlFbzfbrdC7qVrjDFRZoGg\noMR6ejPxpMbwylAdyTf4ofINKkpO0XlqylKiMMaYCLNAUJg6TXTq1zpN9faNLQq9qY8xxtQI1muo\nKI3awo1LIjqazxhjqgILBMUJ9z6kxhhTjVnVkDHGeJwFAmOM8TgLBMYY43EWCIwxxuMsEBhjjMdF\nLBCIyHgR2Soiy4p4XUTkMRFZIyJLRKQGzc1sjDHVRyRLBC8Bg4p5fTBwdODfaODpCKbFGGNMESIW\nCJxzc4Bfi1nlHOAVp74G6otI00ilxxhjTOGi2UbQHNgQ8jwjsOwwIjJaRNJFJD0zM7NMO1v1yy7u\n/2Aluw5klen9xhhTU1WLxmLn3HPOuTTnXFpKSkqZtrHh1/08+/lafty6p4JTZ4wx1Vs0A8FGoGXI\n8xaBZRHRJkVvUr82c2+kdmGMMdVSNAPBdODyQO+hPsBO59zmSO2sZYPaxPiEtdusRGCMMaEiNumc\niEwE+gONRSQDuBOIA3DOPQPMAIYAa4B9wKhIpQUgPtbHUQ1rW4nAGGMKiFggcM4Ve0sv55wDrovU\n/gvTpnGSBQJjjCmgWjQWV5Q2KUn8tH0vOX4X7aQYY0yV4bFAkMyhbD+bduyPdlKMMabK8FYgaKw9\nh37MtAZjY4wJ8lYgSEkGrAupMcaE8lQgaJwcT53EWOtCaowxITwVCESENinJViIwxpgQngoEAG2t\nC6kxxuTjuUDQJiWJX3YdYO/B7GgnxRhjqgQPBgJtMP5pm5UKjDEGPBkIrAupMcaE8lwgSG2UhIh1\nITXGmCDPBYLEuBia16/FWqsaMsYYwIOBAAh0IbWqIWOMAa8GgsZJ/LRtLzoBqjHGeJsnA0HblCT2\nHcrhl10Hop0UY4yJOk8GAptzyBhj8ng0EATvX2ztBMYY48lA0KRuIrXjY/jRSgTGGOPNQCAitG6c\nZF1IjTEGjwYC0HaCn2w6amOM8XAgaJxExm/7OZCVE+2kGGNMVHk3EKQk4Rz8vH1ftJNijDFR5dlA\n0Da3C6lVDxljvM2zgSA1cCN7azA2xnidZwNBckIsR9ZNsOmojTGe59lAANCmsd2/2BhjvB0IUpJY\nm7nHJp8zxniaxwNBMrsOZLN976FoJ8UYY6LG44EgOOeQVQ8ZY7zL04GgbWPrQmqMMZ4OBM0b1CI+\n1mddSI0xnubpQBDjE1Ib1bYSgTHG0zwdCMC6kBpjTEQDgYgMEpHvRWSNiIwt5PWjRGS2iHwnIktE\nZEgk01OYNilJrP91H1k5/sretTHGVAkRCwQiEgM8CQwGOgIjRKRjgdVuByY753oAFwNPRSo9RWmT\nkky237H+V5t8zhjjTZEsEfQG1jjn1jrnDgGTgHMKrOOAuoG/6wGbIpieQgW7kK7YtKuyd22MMVVC\nJANBc2BDyPOMwLJQdwEjRSQDmAFcX9iGRGS0iKSLSHpmZmaFJrJj07q0aFCLf0xbxqpfLBgYY7wn\n2o3FI4CXnHMtgCHAqyJyWJqcc88559Kcc2kpKSkVmoDEuBgmXHM8CbE+Rr7wjU1CZ4zxnEgGgo1A\ny5DnLQLLQl0NTAZwzn0FJAKNI5imQrVqlMSEa/oAcOnz37DeblZjjPGQSAaCb4GjRaS1iMSjjcHT\nC6yzHhgIICId0EBQsXU/YWp3RDKvXn08B7JzuOSFr9m0Y380kmGMMZUuYoHAOZcN/BGYCaxEewct\nF5G7RWRoYLWbgGtFZDEwEbjSRXEq0A5N6/LKVb3ZuS+LS1/4hq27D0QrKcYYU2mkuk3BnJaW5tLT\n0yO6jwU//8pl/5tPiwa1eO2a4zmiTmJE92eMMZEmIgucc2mFvRbtxuIqqVerhrxwRRo/b9/HyQ/O\n5vqJ3zF3dSZ+f/UKmsYYE47YaCegqjqxbWPeu/5kJnyznqnfbeTdxZtoXr8Ww3u1YHivFrRsWDva\nSTTGmAphVUNhOJCVwycrtzA5PYO5qzNxDto3qUOz+rVoUi+RpnUTObJeIk3rJdIwKR6fSO57g38K\nQmyMEOfzERcrxPp8xMf4iI0R/M6R43dk+0Mecxw5zuGcQwsiDucgWCjxCfh8gk9E/xZBBCR03wWO\nw0Hu3diCX7vPJ8T6hBifECNCTIw+D64TfI8LfU9gf8F9Bh9z/A6/0/T7A8fid+Su4wukLzS9JSl4\nega3Ffp3UZsJptkf2Ig/8FmWdM5LYJsi+r3p56p/hx5D8LPO8Tuycvxk+x3ZOX6ycvTY9fNFP1ef\n4At8xsG0+Z1+pwTSKAKxMT7iAueJzxfGB1SCsvy+JZwvxlQ7xVUNWYkgDIlxMZzVtRlndW3Gxh37\neXtBBos27GDzzgMs2rCDX+0OZyYCfAJxMT5ifZIvcGiAdrmZgmCg1r8rNg3BYBsjgs8X+ndesAgN\nNoE8S770+oPpC6Q7mM7QpAYzIrGBgBnrE0TyMkmaQfLj90O2P/+8YKGBKxigY0IyHD6fBnN/IGOi\nGYLA5xfIqEiBzI0UOJa8DFkgrT4hLkYfY32aoQsGeUIegseQleMnK1sfD+X4ycrxk+N3miGM9REX\n4yM+RoiL9eXLiAXTGfwsL+1zFP/Xv115vtJCWSAopeb1a3H9wKPzLTuQlcPWXQfZvHM/v+3LCwqh\nP0q/0xM4KyeYa9S/s3L8uSeW5sx9uT+GGF9o7jeQCw2cZcGT2bm8nHjo/lzIz8y5/CWT0BPVOQIl\nEX++Eknw9dBccaiCJ6jf7/KVLnzBXLDkHX9ojjyYYy6MI39pJrjvvBJKXi4/+AMtKg8bvGDllV4K\nP57Qz8oFSl+u4HOXVyrLvRA7p99ZjF4YYn2+wAVCm99yXGjpKKSkEFIiCv7tQs6RrBw/2TmOLL8+\nBi9w+UsmeeeDSMhnUKCUVJoMfvAcygsswXTnfW/BYyqq5BBaUvP5AmkJLV2FrCcIDt1+jt+f9xjY\nZ4wPYn2+3N9IMGCEnhO5aQ98Tzkh52Tu387lXuiDv6tg+kO/39BzOjSNwc8bAr/l3BKg/l6y/f58\npU2X+58ee0KMXuzjYiVw0dcSX7AEeSjHT1Z23nWBkFK0L+R7b9UwKfwvsxQsEFSAxLgYjmpUm6Ma\nWbuBMab6sV5DxhjjcRYIjDHG4ywQGGOMx1kgMMYYj7NAYIwxHmeBwBhjPM4CgTHGeJwFAmOM8bhq\nN9eQiGQCP5ewWmNgWyUkp6qx4/Yerx67HXfptXLOFXqv32oXCMIhIulFTa5Uk9lxe49Xj92Ou2JZ\n1ZAxxnicBQJjjPG4mhoInot2AqLEjtt7vHrsdtwVqEa2ERhjjAlfTS0RGGOMCZMFAmOM8bgaFwhE\nZJCIfC8ia0RkbLTTEykiMl5EtorIspBlDUXkYxFZHXhsEM00RoKItBSR2SKyQkSWi8iNgeU1+thF\nJFFE5ovI4sBx/zOwvLWIfBM4398QkfhopzUSRCRGRL4TkfcCz2v8cYvIOhFZKiKLRCQ9sCwi53mN\nCgQiEgM8CQwGOgIjRKRjdFMVMS8BgwosGwvMcs4dDcwKPK9psoGbnHMdgT7AdYHvuKYf+0HgVOdc\nN6A7MEhE+gAPAo8459oBvwFXRzGNkXQjsDLkuVeOe4BzrnvI2IGInOc1KhAAvYE1zrm1zrlDwCTg\nnCinKSKcc3OAXwssPgd4OfD3y8C5lZqoSuCc2+ycWxj4ezd6cWhODT92p/YEnsYF/jngVOCtwPIa\nd9wAItICOBN4IfBc8MBxFyEi53lNCwTNgQ0hzzMCy7ziSOfc5sDfvwBHRjMxkSYiqUAP4Bs8cOyB\n6pFFwFbgY+BHYIdzLjuwSk093x8F/gr4A88b4Y3jdsBHIrJAREYHlkXkPLeb19dQzjknIjW2b7CI\nJANTgD8553ZpJlHV1GN3zuUA3UWkPjAVaB/lJEWciJwFbHXOLRCR/tFOTyU72Tm3UUSOAD4WkVWh\nL1bkeV7TSgQbgZYhz1sElnnFFhFpChB43Brl9ESEiMShQWCCc+7twGJPHDuAc24HMBs4AagvIsEM\nXU08308ChorIOrSq91Tgv9T848Y5tzHwuBUN/L2J0Hle0wLBt8DRgR4F8cDFwPQop6kyTQeuCPx9\nBTAtimmJiED98P+Alc65cSEv1ehjF5GUQEkAEakF/A5tH5kNDA+sVuOO2zn3N+dcC+dcKvp7/tQ5\ndyk1/LhFJElE6gT/Bk4HlhGh87zGjSwWkSFonWIMMN45d1+UkxQRIjIR6I9OS7sFuBN4B5gMHIVO\n1X2hc65gg3K1JiInA3OBpeTVGd+GthPU2GMXka5o42AMmoGb7Jy7W0TaoDnlhsB3wEjn3MHopTRy\nAlVDNzvnzqrpxx04vqmBp7HA6865+0SkERE4z2tcIDDGGFM6Na1qyBhjTClZIDDGGI+zQGCMMR5n\ngcAYYzzOAoExxnicBQJjAkQkJzDTY/BfhU1cJyKpoTPFGlOV2BQTxuTZ75zrHu1EGFPZrERgTAkC\n88I/FJgbfr6ItAssTxWRT0VkiYjMEpGjAsuPFJGpgXsHLBaREwObihGR5wP3E/goMEIYEbkhcH+F\nJSIyKUqHaTzMAoExeWoVqBq6KOS1nc65LsAT6Mh1gMeBl51zXYEJwGOB5Y8BnwfuHdATWB5YfjTw\npHOuE7ADOD+wfCzQI7CdP0Tq4Iwpio0sNiZARPY455ILWb4OvSnM2sCEd7845xqJyDagqXMuK7B8\ns3OusYhkAi1CpzwITJn9ceCGIojIrUCcc+5eEfkQ2INOEfJOyH0HjKkUViIwJjyuiL9LI3QunBzy\n2ujORO+s1xP4NmRWTWMqhQUCY8JzUcjjV4G/56EzYgJcik6GB3oLwTGQezOZekVtVER8QEvn3Gzg\nVqAecFipxJhIspyHMXlqBe4AFvShcy7YhbSBiCxBc/UjAsuuB14UkVuATGBUYPmNwHMicjWa8x8D\nbKZwMcBrgWAhwGOB+w0YU2msjcCYEgTaCNKcc9uinRZjIsGqhowxxuOsRGCMMR5nJQJjjPE4CwTG\nGONxFgiMMcbjLBAYY4zHWSAwxhiP+39/9taVaJFMogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nj5IaELEEAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "65e480f5-01ff-418f-d6e0-704a88129b65"
      },
      "source": [
        "train_df, val_df = split_train_val(train_df)\n",
        "train_data, val_data = split_train_val(train_df)\n",
        "(train_X, train_y), (val_X, val_y), (test_X, test_y)  = prep(train_data, val_data, test_df)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (203488, 4)\n",
            "Test shape :  (144006, 4)\n",
            "Train shape :  (162790, 4)\n",
            "Test shape :  (144006, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjiSevGB6mKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "aa379a01-c060-482a-8366-289aea0cb087"
      },
      "source": [
        "m = build_model(np.shape(train_X)[1])\n",
        "train_mae, val_mae = train_model(m, epochs=5, b_size=512)\n",
        "test_mse, test_mae = m.evaluate(test_X, test_y)\n",
        "test_mae"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 162790 samples, validate on 40698 samples\n",
            "Epoch 1/5\n",
            "162790/162790 [==============================] - 3s 19us/step - loss: 3.9119 - mean_absolute_error: 1.1300 - val_loss: 4.5657 - val_mean_absolute_error: 1.5969\n",
            "Epoch 2/5\n",
            "162790/162790 [==============================] - 2s 14us/step - loss: 2.3195 - mean_absolute_error: 0.9202 - val_loss: 1.9243 - val_mean_absolute_error: 0.8810\n",
            "Epoch 3/5\n",
            "162790/162790 [==============================] - 2s 14us/step - loss: 1.6631 - mean_absolute_error: 0.8452 - val_loss: 1.4065 - val_mean_absolute_error: 0.8072\n",
            "Epoch 4/5\n",
            "162790/162790 [==============================] - 2s 14us/step - loss: 1.3870 - mean_absolute_error: 0.8221 - val_loss: 1.2740 - val_mean_absolute_error: 0.7974\n",
            "Epoch 5/5\n",
            "162790/162790 [==============================] - 2s 15us/step - loss: 1.2828 - mean_absolute_error: 0.8129 - val_loss: 1.2457 - val_mean_absolute_error: 0.7994\n",
            "144006/144006 [==============================] - 10s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9769205460134099"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}