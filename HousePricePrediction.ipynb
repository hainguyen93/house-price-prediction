{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousePricePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwGJ-vhbujb",
        "colab_type": "code",
        "outputId": "0d858dc8-d6ea-432c-bdba-74a19fb00985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model, Sequential\n",
        "from keras.metrics import mean_absolute_error, mae, mse\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.regularizers import l2, l1_l2\n",
        "\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1v4zYdqej0k",
        "colab_type": "code",
        "outputId": "c099d59b-e682-4f82-8c2f-8fcfaf70c29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erff7ShwIGKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(url, columns=[1, 2, 4, 6, 11]):\n",
        "  df = pd.read_csv(url, header=None, usecols=columns)\n",
        "  print('Data shape: ', np.shape(df))\n",
        "\n",
        "  # re-name all columns\n",
        "  column_names = ['Price', 'PurchaseDate', 'PropertyType', 'LeaseDuration', 'City']\n",
        "  df.columns = column_names\n",
        "  \n",
        "  # resplace column values\n",
        "  df['PropertyType'] = df['PropertyType'].replace({'F':0, 'D':1, 'S':2, 'T':3, 'O':4})\n",
        "  df['LeaseDuration'] = df['LeaseDuration'].replace({'L':0, 'F':1, 'U':2})\n",
        "  df.loc[df['City']=='LONDON', 'City'] = 0\n",
        "  df.loc[df['City'] != 0, 'City'] = 1\n",
        "\n",
        "  # convert column values to appropriate dtype to save memory\n",
        "  df['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'])\n",
        "  df['Price'] = pd.to_numeric(df[\"Price\"], downcast=\"integer\")\n",
        "  df['PropertyType'] = pd.to_numeric(df['PropertyType'], downcast='integer')\n",
        "  df['LeaseDuration'] = pd.to_numeric(df[\"LeaseDuration\"], downcast=\"integer\")\n",
        "  df['City'] = pd.to_numeric(df[\"City\"], downcast=\"integer\")\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXQfJ7yd3P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(df):\n",
        "  cutoff = datetime(2016, 1, 1)\n",
        "  column_sels = ['Price', 'PropertyType', 'LeaseDuration', 'City']\n",
        "  train_df = df.loc[df['PurchaseDate'] <= cutoff][column_sels]\n",
        "  test_df = df.loc[df['PurchaseDate'] > cutoff][column_sels] \n",
        "  \n",
        "  # remove duplicates\n",
        "  train_df.drop_duplicates(keep='first', inplace=True)\n",
        "  test_df.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "  return train_df, test_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kI469W9I02n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(train_df):\n",
        "  # split to train and val (~20%)\n",
        "  train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=2019)\n",
        "  print(\"Train shape : \", train_df.shape)\n",
        "  print(\"Test shape : \", test_df.shape)\n",
        "  \n",
        "  return train_df, val_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "807FFQwiJW8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep(train_df, val_df, test_df):\n",
        "  # training data\n",
        "  train_X = train_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  train_y = train_df['Price']\n",
        "\n",
        "  val_X = val_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  val_y = val_df['Price']\n",
        "\n",
        "  # testing data\n",
        "  test_X = test_df[['PropertyType', 'LeaseDuration', 'City']]\n",
        "  test_y = test_df['Price']\n",
        "\n",
        "  # one-hot encoding the inputs\n",
        "  ohc = OneHotEncoder(handle_unknown='ignore')\n",
        "  ohc.fit(train_X)\n",
        "  train_X = ohc.transform(train_X)\n",
        "  val_X = ohc.transform(val_X)\n",
        "  test_X = ohc.transform(test_X)\n",
        "\n",
        "  # convert the targets to smaller range\n",
        "  train_y = np.log1p(train_y * 1e-3)\n",
        "  val_y = np.log1p(val_y * 1e-3)\n",
        "  test_y = np.log1p(test_y * 1e-3)\n",
        "\n",
        "  return (train_X, train_y), (val_X, val_y), (test_X, test_y)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur0vmdiu1IDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_size):\n",
        "  \"\"\" Build the model with many fully connected layers  \n",
        "  \"\"\"\n",
        "  inp = Input(shape=(input_size,))\n",
        "  fc1 = Dense(100, activation='relu', kernel_regularizer=l2(0.001))(inp)\n",
        "  do1 = Dropout(0.5)(fc1)\n",
        "  fc2 = Dense(200, activation='relu', kernel_regularizer=l2(0.001))(do1)\n",
        "  do2 = Dropout(0.5)(fc2)\n",
        "  fc3 = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(do2)\n",
        "  do3 = Dropout(0.5)(fc3)\n",
        "  fc4 = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(do3)\n",
        "  out = Dense(1)(fc4)\n",
        "\n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(optimizer=RMSprop(lr=1e-3), loss=mse, metrics=[mae])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwzVEw54HPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, epochs=10, b_size=10000):\n",
        "  \"\"\" Perform model traning  \n",
        "  \"\"\"\n",
        "  history = model.fit(train_X, train_y, batch_size=b_size, verbose=1,\n",
        "                      epochs=epochs, validation_data=(val_X, val_y))\n",
        "  \n",
        "  train_mae = history.history['mean_absolute_error']\n",
        "  val_mae = history.history['val_mean_absolute_error']\n",
        "  \n",
        "  return train_mae, val_mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKWXA96351JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_val_error_plotter(train_mae, val_mae):\n",
        "  \"\"\" Plot the train/val loss over epochs\n",
        "  \"\"\"\n",
        "  epochs = len(train_mae)\n",
        "  plt.plot(range(1, epochs+1), train_mae, label='Training Loss')\n",
        "  plt.plot(range(1, epochs+1), val_mae, label='Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw_71SZg63Ei",
        "colab_type": "code",
        "outputId": "260f8c46-823e-4f39-e3fc-31b5dbe971e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = '/content/drive/My Drive/pp-complete.csv'\n",
        "\n",
        "df = load_data(url)\n",
        "train_df, test_df = split_train_test(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape:  (24852949, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0r8CEzb9UGt",
        "colab_type": "code",
        "outputId": "3527a4af-5cdb-4fac-aa93-2fcd7042a042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fitting the model using cross validation with k folds\n",
        "k = 5\n",
        "num_samples = np.shape(train_df)[0] // k\n",
        "num_epochs = 50\n",
        "b_size = 512\n",
        "train_errors = []\n",
        "val_errors = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold {0}'.format(i))\n",
        "  val_data = train_df.iloc[i*num_samples:(i+1)*num_samples]\n",
        "  train_data = pd.concat([train_df.iloc[:i*num_samples], train_df.iloc[(i+1)*num_samples:]])\n",
        "\n",
        "  (train_X, train_y), (val_X, val_y), (test_X, test_y) = prep(train_data, val_data, test_df)\n",
        "  model = build_model(np.shape(train_X)[1])\n",
        "  train_mae, val_mae = train_model(model, num_epochs, b_size)\n",
        "  train_errors.append(train_mae)\n",
        "  val_errors.append(val_mae)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "254362/254362 [==============================] - 8s 33us/step - loss: 3.3545 - mean_absolute_error: 1.0219 - val_loss: 2.0650 - val_mean_absolute_error: 0.7883\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.7308 - mean_absolute_error: 0.7953 - val_loss: 2.7014 - val_mean_absolute_error: 1.3019\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2160 - mean_absolute_error: 0.7468 - val_loss: 1.9883 - val_mean_absolute_error: 1.1252\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0794 - mean_absolute_error: 0.7328 - val_loss: 1.8273 - val_mean_absolute_error: 1.0861\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0336 - mean_absolute_error: 0.7264 - val_loss: 2.0134 - val_mean_absolute_error: 1.1564\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0276 - mean_absolute_error: 0.7263 - val_loss: 1.9983 - val_mean_absolute_error: 1.1490\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0249 - mean_absolute_error: 0.7260 - val_loss: 2.1836 - val_mean_absolute_error: 1.2196\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0240 - mean_absolute_error: 0.7262 - val_loss: 1.9076 - val_mean_absolute_error: 1.1237\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0212 - mean_absolute_error: 0.7255 - val_loss: 2.0260 - val_mean_absolute_error: 1.1624\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0203 - mean_absolute_error: 0.7257 - val_loss: 1.9170 - val_mean_absolute_error: 1.1247\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0200 - mean_absolute_error: 0.7256 - val_loss: 1.9741 - val_mean_absolute_error: 1.1462\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7253 - val_loss: 1.9593 - val_mean_absolute_error: 1.1441\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7250 - val_loss: 1.9202 - val_mean_absolute_error: 1.1287\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0174 - mean_absolute_error: 0.7247 - val_loss: 2.1075 - val_mean_absolute_error: 1.1923\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0161 - mean_absolute_error: 0.7248 - val_loss: 2.1747 - val_mean_absolute_error: 1.2133\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0137 - mean_absolute_error: 0.7245 - val_loss: 2.0973 - val_mean_absolute_error: 1.1885\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0150 - mean_absolute_error: 0.7249 - val_loss: 2.3106 - val_mean_absolute_error: 1.2604\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0138 - mean_absolute_error: 0.7244 - val_loss: 2.0239 - val_mean_absolute_error: 1.1617\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0137 - mean_absolute_error: 0.7247 - val_loss: 2.1605 - val_mean_absolute_error: 1.2083\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0135 - mean_absolute_error: 0.7243 - val_loss: 2.2691 - val_mean_absolute_error: 1.2522\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0122 - mean_absolute_error: 0.7243 - val_loss: 2.1055 - val_mean_absolute_error: 1.1947\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0131 - mean_absolute_error: 0.7242 - val_loss: 2.0382 - val_mean_absolute_error: 1.1632\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0126 - mean_absolute_error: 0.7244 - val_loss: 1.8901 - val_mean_absolute_error: 1.1186\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0129 - mean_absolute_error: 0.7245 - val_loss: 2.0101 - val_mean_absolute_error: 1.1598\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0121 - mean_absolute_error: 0.7244 - val_loss: 1.9934 - val_mean_absolute_error: 1.1518\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0109 - mean_absolute_error: 0.7243 - val_loss: 1.7894 - val_mean_absolute_error: 1.0804\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0114 - mean_absolute_error: 0.7242 - val_loss: 1.9428 - val_mean_absolute_error: 1.1340\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0102 - mean_absolute_error: 0.7241 - val_loss: 2.1746 - val_mean_absolute_error: 1.2105\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0081 - mean_absolute_error: 0.7240 - val_loss: 2.0574 - val_mean_absolute_error: 1.1746\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0094 - mean_absolute_error: 0.7239 - val_loss: 1.8889 - val_mean_absolute_error: 1.1164\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0095 - mean_absolute_error: 0.7242 - val_loss: 1.9320 - val_mean_absolute_error: 1.1348\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0093 - mean_absolute_error: 0.7242 - val_loss: 2.0778 - val_mean_absolute_error: 1.1841\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0097 - mean_absolute_error: 0.7244 - val_loss: 2.0978 - val_mean_absolute_error: 1.1892\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0093 - mean_absolute_error: 0.7240 - val_loss: 2.0175 - val_mean_absolute_error: 1.1602\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0094 - mean_absolute_error: 0.7243 - val_loss: 2.1557 - val_mean_absolute_error: 1.2077\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0091 - mean_absolute_error: 0.7238 - val_loss: 1.9862 - val_mean_absolute_error: 1.1501\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0098 - mean_absolute_error: 0.7243 - val_loss: 1.8905 - val_mean_absolute_error: 1.1153\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0082 - mean_absolute_error: 0.7242 - val_loss: 2.0864 - val_mean_absolute_error: 1.1886\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0077 - mean_absolute_error: 0.7239 - val_loss: 1.9533 - val_mean_absolute_error: 1.1401\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0082 - mean_absolute_error: 0.7243 - val_loss: 2.3963 - val_mean_absolute_error: 1.2844\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0075 - mean_absolute_error: 0.7238 - val_loss: 2.1031 - val_mean_absolute_error: 1.1999\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0065 - mean_absolute_error: 0.7237 - val_loss: 1.9433 - val_mean_absolute_error: 1.1362\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0075 - mean_absolute_error: 0.7238 - val_loss: 1.8749 - val_mean_absolute_error: 1.1120\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0078 - mean_absolute_error: 0.7240 - val_loss: 2.0416 - val_mean_absolute_error: 1.1699\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0061 - mean_absolute_error: 0.7239 - val_loss: 2.2738 - val_mean_absolute_error: 1.2505\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0068 - mean_absolute_error: 0.7239 - val_loss: 2.1674 - val_mean_absolute_error: 1.2189\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0063 - mean_absolute_error: 0.7238 - val_loss: 1.7660 - val_mean_absolute_error: 1.0650\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0065 - mean_absolute_error: 0.7241 - val_loss: 2.1691 - val_mean_absolute_error: 1.2163\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0060 - mean_absolute_error: 0.7239 - val_loss: 2.0275 - val_mean_absolute_error: 1.1689\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.0067 - mean_absolute_error: 0.7237 - val_loss: 1.9914 - val_mean_absolute_error: 1.1533\n",
            "processing fold 1\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 16us/step - loss: 3.4311 - mean_absolute_error: 1.0535 - val_loss: 1.8213 - val_mean_absolute_error: 0.7261\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.8224 - mean_absolute_error: 0.8498 - val_loss: 1.3340 - val_mean_absolute_error: 0.8147\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.3685 - mean_absolute_error: 0.8128 - val_loss: 1.0665 - val_mean_absolute_error: 0.7572\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2451 - mean_absolute_error: 0.8003 - val_loss: 1.0848 - val_mean_absolute_error: 0.7956\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2049 - mean_absolute_error: 0.7948 - val_loss: 1.1063 - val_mean_absolute_error: 0.8101\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1992 - mean_absolute_error: 0.7944 - val_loss: 1.0584 - val_mean_absolute_error: 0.7883\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1947 - mean_absolute_error: 0.7934 - val_loss: 1.1567 - val_mean_absolute_error: 0.8368\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1918 - mean_absolute_error: 0.7927 - val_loss: 1.0692 - val_mean_absolute_error: 0.7953\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1909 - mean_absolute_error: 0.7929 - val_loss: 1.1118 - val_mean_absolute_error: 0.8168\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1886 - mean_absolute_error: 0.7927 - val_loss: 1.0959 - val_mean_absolute_error: 0.8084\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1892 - mean_absolute_error: 0.7930 - val_loss: 1.1255 - val_mean_absolute_error: 0.8246\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1873 - mean_absolute_error: 0.7926 - val_loss: 1.1454 - val_mean_absolute_error: 0.8335\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1875 - mean_absolute_error: 0.7928 - val_loss: 1.0691 - val_mean_absolute_error: 0.7971\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1854 - mean_absolute_error: 0.7923 - val_loss: 1.0665 - val_mean_absolute_error: 0.7948\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1854 - mean_absolute_error: 0.7924 - val_loss: 1.1285 - val_mean_absolute_error: 0.8266\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1833 - mean_absolute_error: 0.7919 - val_loss: 1.1535 - val_mean_absolute_error: 0.8382\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1857 - mean_absolute_error: 0.7924 - val_loss: 1.0652 - val_mean_absolute_error: 0.7961\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1835 - mean_absolute_error: 0.7923 - val_loss: 1.0650 - val_mean_absolute_error: 0.7966\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1816 - mean_absolute_error: 0.7917 - val_loss: 1.0518 - val_mean_absolute_error: 0.7889\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1836 - mean_absolute_error: 0.7923 - val_loss: 1.0944 - val_mean_absolute_error: 0.8112\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1838 - mean_absolute_error: 0.7924 - val_loss: 1.0599 - val_mean_absolute_error: 0.7949\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1836 - mean_absolute_error: 0.7926 - val_loss: 1.0947 - val_mean_absolute_error: 0.8108\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1847 - mean_absolute_error: 0.7923 - val_loss: 1.1093 - val_mean_absolute_error: 0.8181\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1820 - mean_absolute_error: 0.7922 - val_loss: 1.1886 - val_mean_absolute_error: 0.8551\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1815 - mean_absolute_error: 0.7921 - val_loss: 1.1919 - val_mean_absolute_error: 0.8557\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1818 - mean_absolute_error: 0.7923 - val_loss: 1.0885 - val_mean_absolute_error: 0.8083\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1810 - mean_absolute_error: 0.7920 - val_loss: 1.0964 - val_mean_absolute_error: 0.8131\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1822 - mean_absolute_error: 0.7922 - val_loss: 1.1523 - val_mean_absolute_error: 0.8391\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1814 - mean_absolute_error: 0.7921 - val_loss: 1.0498 - val_mean_absolute_error: 0.7900\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1809 - mean_absolute_error: 0.7922 - val_loss: 1.1763 - val_mean_absolute_error: 0.8498\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1801 - mean_absolute_error: 0.7919 - val_loss: 1.1440 - val_mean_absolute_error: 0.8352\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1811 - mean_absolute_error: 0.7920 - val_loss: 1.1700 - val_mean_absolute_error: 0.8467\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1802 - mean_absolute_error: 0.7921 - val_loss: 1.2228 - val_mean_absolute_error: 0.8707\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1815 - mean_absolute_error: 0.7923 - val_loss: 1.0678 - val_mean_absolute_error: 0.7987\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1803 - mean_absolute_error: 0.7921 - val_loss: 1.1162 - val_mean_absolute_error: 0.8229\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1777 - mean_absolute_error: 0.7913 - val_loss: 1.1913 - val_mean_absolute_error: 0.8566\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1790 - mean_absolute_error: 0.7919 - val_loss: 1.0373 - val_mean_absolute_error: 0.7848\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1789 - mean_absolute_error: 0.7918 - val_loss: 1.1474 - val_mean_absolute_error: 0.8373\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1797 - mean_absolute_error: 0.7922 - val_loss: 1.1263 - val_mean_absolute_error: 0.8271\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1780 - mean_absolute_error: 0.7917 - val_loss: 1.1583 - val_mean_absolute_error: 0.8423\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1795 - mean_absolute_error: 0.7919 - val_loss: 1.1079 - val_mean_absolute_error: 0.8196\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1796 - mean_absolute_error: 0.7921 - val_loss: 1.1073 - val_mean_absolute_error: 0.8186\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1780 - mean_absolute_error: 0.7920 - val_loss: 1.1701 - val_mean_absolute_error: 0.8475\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1767 - mean_absolute_error: 0.7914 - val_loss: 1.0653 - val_mean_absolute_error: 0.7971\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1776 - mean_absolute_error: 0.7916 - val_loss: 1.2013 - val_mean_absolute_error: 0.8622\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1770 - mean_absolute_error: 0.7917 - val_loss: 1.1335 - val_mean_absolute_error: 0.8308\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1780 - mean_absolute_error: 0.7920 - val_loss: 1.1569 - val_mean_absolute_error: 0.8414\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.1778 - mean_absolute_error: 0.7913 - val_loss: 1.1083 - val_mean_absolute_error: 0.8188\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1765 - mean_absolute_error: 0.7915 - val_loss: 1.1684 - val_mean_absolute_error: 0.8465\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1778 - mean_absolute_error: 0.7919 - val_loss: 1.1108 - val_mean_absolute_error: 0.8206\n",
            "processing fold 2\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 16us/step - loss: 3.4995 - mean_absolute_error: 1.0781 - val_loss: 1.8848 - val_mean_absolute_error: 0.8125\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.8585 - mean_absolute_error: 0.8848 - val_loss: 1.0667 - val_mean_absolute_error: 0.6880\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.4498 - mean_absolute_error: 0.8557 - val_loss: 0.8193 - val_mean_absolute_error: 0.6262\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.3323 - mean_absolute_error: 0.8463 - val_loss: 0.7649 - val_mean_absolute_error: 0.6267\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2874 - mean_absolute_error: 0.8410 - val_loss: 0.7662 - val_mean_absolute_error: 0.6352\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2785 - mean_absolute_error: 0.8395 - val_loss: 0.7714 - val_mean_absolute_error: 0.6426\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2741 - mean_absolute_error: 0.8390 - val_loss: 0.7674 - val_mean_absolute_error: 0.6397\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2733 - mean_absolute_error: 0.8396 - val_loss: 0.7811 - val_mean_absolute_error: 0.6507\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2712 - mean_absolute_error: 0.8387 - val_loss: 0.7667 - val_mean_absolute_error: 0.6410\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2690 - mean_absolute_error: 0.8389 - val_loss: 0.7633 - val_mean_absolute_error: 0.6402\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2696 - mean_absolute_error: 0.8389 - val_loss: 0.7973 - val_mean_absolute_error: 0.6625\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2701 - mean_absolute_error: 0.8394 - val_loss: 0.7421 - val_mean_absolute_error: 0.6270\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2672 - mean_absolute_error: 0.8386 - val_loss: 0.7890 - val_mean_absolute_error: 0.6600\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2669 - mean_absolute_error: 0.8387 - val_loss: 0.8132 - val_mean_absolute_error: 0.6704\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2661 - mean_absolute_error: 0.8383 - val_loss: 0.7897 - val_mean_absolute_error: 0.6586\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2659 - mean_absolute_error: 0.8381 - val_loss: 0.7419 - val_mean_absolute_error: 0.6291\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2643 - mean_absolute_error: 0.8381 - val_loss: 0.7551 - val_mean_absolute_error: 0.6377\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2636 - mean_absolute_error: 0.8382 - val_loss: 0.7657 - val_mean_absolute_error: 0.6420\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2641 - mean_absolute_error: 0.8381 - val_loss: 0.7664 - val_mean_absolute_error: 0.6461\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2635 - mean_absolute_error: 0.8384 - val_loss: 0.8143 - val_mean_absolute_error: 0.6733\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2611 - mean_absolute_error: 0.8379 - val_loss: 0.7443 - val_mean_absolute_error: 0.6317\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2631 - mean_absolute_error: 0.8381 - val_loss: 0.7839 - val_mean_absolute_error: 0.6554\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2623 - mean_absolute_error: 0.8382 - val_loss: 0.7587 - val_mean_absolute_error: 0.6423\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2612 - mean_absolute_error: 0.8377 - val_loss: 0.7581 - val_mean_absolute_error: 0.6408\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2620 - mean_absolute_error: 0.8379 - val_loss: 0.7503 - val_mean_absolute_error: 0.6341\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2608 - mean_absolute_error: 0.8376 - val_loss: 0.7559 - val_mean_absolute_error: 0.6376\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2612 - mean_absolute_error: 0.8382 - val_loss: 0.7711 - val_mean_absolute_error: 0.6491\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2607 - mean_absolute_error: 0.8377 - val_loss: 0.7355 - val_mean_absolute_error: 0.6215\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2613 - mean_absolute_error: 0.8380 - val_loss: 0.7643 - val_mean_absolute_error: 0.6454\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2600 - mean_absolute_error: 0.8377 - val_loss: 0.7602 - val_mean_absolute_error: 0.6448\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2598 - mean_absolute_error: 0.8376 - val_loss: 0.7440 - val_mean_absolute_error: 0.6318\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2600 - mean_absolute_error: 0.8379 - val_loss: 0.7685 - val_mean_absolute_error: 0.6478\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2568 - mean_absolute_error: 0.8373 - val_loss: 0.7591 - val_mean_absolute_error: 0.6411\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2608 - mean_absolute_error: 0.8378 - val_loss: 0.7497 - val_mean_absolute_error: 0.6337\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2581 - mean_absolute_error: 0.8376 - val_loss: 0.7530 - val_mean_absolute_error: 0.6372\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2594 - mean_absolute_error: 0.8378 - val_loss: 0.7510 - val_mean_absolute_error: 0.6399\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2577 - mean_absolute_error: 0.8375 - val_loss: 0.7474 - val_mean_absolute_error: 0.6333\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2578 - mean_absolute_error: 0.8372 - val_loss: 0.7326 - val_mean_absolute_error: 0.6253\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2585 - mean_absolute_error: 0.8380 - val_loss: 0.7746 - val_mean_absolute_error: 0.6525\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2588 - mean_absolute_error: 0.8381 - val_loss: 0.7505 - val_mean_absolute_error: 0.6380\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2578 - mean_absolute_error: 0.8371 - val_loss: 0.7773 - val_mean_absolute_error: 0.6531\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2572 - mean_absolute_error: 0.8376 - val_loss: 0.7406 - val_mean_absolute_error: 0.6308\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2574 - mean_absolute_error: 0.8374 - val_loss: 0.7829 - val_mean_absolute_error: 0.6563\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2569 - mean_absolute_error: 0.8374 - val_loss: 0.7651 - val_mean_absolute_error: 0.6450\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2562 - mean_absolute_error: 0.8375 - val_loss: 0.7417 - val_mean_absolute_error: 0.6302\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2572 - mean_absolute_error: 0.8373 - val_loss: 0.7426 - val_mean_absolute_error: 0.6327\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2546 - mean_absolute_error: 0.8367 - val_loss: 0.8082 - val_mean_absolute_error: 0.6706\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2547 - mean_absolute_error: 0.8368 - val_loss: 0.7834 - val_mean_absolute_error: 0.6579\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2573 - mean_absolute_error: 0.8376 - val_loss: 0.7594 - val_mean_absolute_error: 0.6429\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2561 - mean_absolute_error: 0.8373 - val_loss: 0.7348 - val_mean_absolute_error: 0.6284\n",
            "processing fold 3\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 17us/step - loss: 3.4648 - mean_absolute_error: 1.0828 - val_loss: 2.0436 - val_mean_absolute_error: 0.8935\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.8234 - mean_absolute_error: 0.8868 - val_loss: 0.9928 - val_mean_absolute_error: 0.6471\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.4266 - mean_absolute_error: 0.8585 - val_loss: 0.7612 - val_mean_absolute_error: 0.5869\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.3231 - mean_absolute_error: 0.8490 - val_loss: 0.9167 - val_mean_absolute_error: 0.7003\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2829 - mean_absolute_error: 0.8430 - val_loss: 0.9019 - val_mean_absolute_error: 0.6994\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2744 - mean_absolute_error: 0.8415 - val_loss: 0.8553 - val_mean_absolute_error: 0.6749\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2702 - mean_absolute_error: 0.8412 - val_loss: 0.9602 - val_mean_absolute_error: 0.7339\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2707 - mean_absolute_error: 0.8417 - val_loss: 0.9086 - val_mean_absolute_error: 0.7034\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2667 - mean_absolute_error: 0.8408 - val_loss: 0.8416 - val_mean_absolute_error: 0.6683\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2656 - mean_absolute_error: 0.8414 - val_loss: 0.8298 - val_mean_absolute_error: 0.6628\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2645 - mean_absolute_error: 0.8408 - val_loss: 0.7947 - val_mean_absolute_error: 0.6466\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2620 - mean_absolute_error: 0.8404 - val_loss: 0.7835 - val_mean_absolute_error: 0.6396\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2608 - mean_absolute_error: 0.8405 - val_loss: 0.8889 - val_mean_absolute_error: 0.6959\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2614 - mean_absolute_error: 0.8404 - val_loss: 0.8428 - val_mean_absolute_error: 0.6728\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2610 - mean_absolute_error: 0.8406 - val_loss: 0.8070 - val_mean_absolute_error: 0.6542\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2599 - mean_absolute_error: 0.8403 - val_loss: 0.9079 - val_mean_absolute_error: 0.7111\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2597 - mean_absolute_error: 0.8402 - val_loss: 0.7824 - val_mean_absolute_error: 0.6404\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2583 - mean_absolute_error: 0.8398 - val_loss: 0.8131 - val_mean_absolute_error: 0.6581\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2575 - mean_absolute_error: 0.8399 - val_loss: 0.8126 - val_mean_absolute_error: 0.6577\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2589 - mean_absolute_error: 0.8402 - val_loss: 0.8484 - val_mean_absolute_error: 0.6797\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2573 - mean_absolute_error: 0.8401 - val_loss: 0.8723 - val_mean_absolute_error: 0.6917\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2572 - mean_absolute_error: 0.8405 - val_loss: 0.8642 - val_mean_absolute_error: 0.6855\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2570 - mean_absolute_error: 0.8401 - val_loss: 0.7927 - val_mean_absolute_error: 0.6442\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2557 - mean_absolute_error: 0.8395 - val_loss: 0.9749 - val_mean_absolute_error: 0.7458\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2556 - mean_absolute_error: 0.8399 - val_loss: 0.8142 - val_mean_absolute_error: 0.6626\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2569 - mean_absolute_error: 0.8399 - val_loss: 0.7628 - val_mean_absolute_error: 0.6279\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2545 - mean_absolute_error: 0.8395 - val_loss: 0.8452 - val_mean_absolute_error: 0.6757\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2564 - mean_absolute_error: 0.8400 - val_loss: 0.9050 - val_mean_absolute_error: 0.7097\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2536 - mean_absolute_error: 0.8396 - val_loss: 0.8749 - val_mean_absolute_error: 0.6924\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2534 - mean_absolute_error: 0.8396 - val_loss: 0.7255 - val_mean_absolute_error: 0.6115\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2534 - mean_absolute_error: 0.8396 - val_loss: 0.8236 - val_mean_absolute_error: 0.6640\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2535 - mean_absolute_error: 0.8397 - val_loss: 0.7915 - val_mean_absolute_error: 0.6461\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2536 - mean_absolute_error: 0.8397 - val_loss: 0.6914 - val_mean_absolute_error: 0.5915\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2526 - mean_absolute_error: 0.8395 - val_loss: 0.8493 - val_mean_absolute_error: 0.6811\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2526 - mean_absolute_error: 0.8397 - val_loss: 0.8340 - val_mean_absolute_error: 0.6716\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2524 - mean_absolute_error: 0.8396 - val_loss: 0.8694 - val_mean_absolute_error: 0.6901\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2540 - mean_absolute_error: 0.8396 - val_loss: 0.8609 - val_mean_absolute_error: 0.6860\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2514 - mean_absolute_error: 0.8390 - val_loss: 0.8646 - val_mean_absolute_error: 0.6884\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2524 - mean_absolute_error: 0.8393 - val_loss: 0.9201 - val_mean_absolute_error: 0.7171\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2521 - mean_absolute_error: 0.8393 - val_loss: 0.7289 - val_mean_absolute_error: 0.6092\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2499 - mean_absolute_error: 0.8388 - val_loss: 0.8716 - val_mean_absolute_error: 0.6926\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2527 - mean_absolute_error: 0.8399 - val_loss: 0.7469 - val_mean_absolute_error: 0.6233\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2507 - mean_absolute_error: 0.8397 - val_loss: 0.8481 - val_mean_absolute_error: 0.6804\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2521 - mean_absolute_error: 0.8397 - val_loss: 0.8148 - val_mean_absolute_error: 0.6592\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2501 - mean_absolute_error: 0.8393 - val_loss: 0.7994 - val_mean_absolute_error: 0.6507\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2507 - mean_absolute_error: 0.8395 - val_loss: 0.9267 - val_mean_absolute_error: 0.7219\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2501 - mean_absolute_error: 0.8391 - val_loss: 0.7565 - val_mean_absolute_error: 0.6293\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.2481 - mean_absolute_error: 0.8389 - val_loss: 0.8151 - val_mean_absolute_error: 0.6590\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2502 - mean_absolute_error: 0.8392 - val_loss: 0.7905 - val_mean_absolute_error: 0.6495\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 1.2496 - mean_absolute_error: 0.8390 - val_loss: 0.8284 - val_mean_absolute_error: 0.6675\n",
            "processing fold 4\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 51,601\n",
            "Trainable params: 51,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 254362 samples, validate on 63590 samples\n",
            "Epoch 1/50\n",
            "254362/254362 [==============================] - 4s 17us/step - loss: 3.0815 - mean_absolute_error: 0.9926 - val_loss: 4.8144 - val_mean_absolute_error: 1.6906\n",
            "Epoch 2/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.5238 - mean_absolute_error: 0.7987 - val_loss: 2.3776 - val_mean_absolute_error: 1.0813\n",
            "Epoch 3/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.1294 - mean_absolute_error: 0.7681 - val_loss: 2.1731 - val_mean_absolute_error: 1.0490\n",
            "Epoch 4/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0302 - mean_absolute_error: 0.7567 - val_loss: 2.2799 - val_mean_absolute_error: 1.0996\n",
            "Epoch 5/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0074 - mean_absolute_error: 0.7535 - val_loss: 2.3131 - val_mean_absolute_error: 1.1122\n",
            "Epoch 6/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0031 - mean_absolute_error: 0.7535 - val_loss: 2.1766 - val_mean_absolute_error: 1.0606\n",
            "Epoch 7/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0013 - mean_absolute_error: 0.7529 - val_loss: 2.3899 - val_mean_absolute_error: 1.1432\n",
            "Epoch 8/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0009 - mean_absolute_error: 0.7533 - val_loss: 2.3903 - val_mean_absolute_error: 1.1392\n",
            "Epoch 9/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 1.0006 - mean_absolute_error: 0.7535 - val_loss: 2.4037 - val_mean_absolute_error: 1.1453\n",
            "Epoch 10/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9998 - mean_absolute_error: 0.7532 - val_loss: 2.4256 - val_mean_absolute_error: 1.1541\n",
            "Epoch 11/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9977 - mean_absolute_error: 0.7532 - val_loss: 2.5893 - val_mean_absolute_error: 1.2115\n",
            "Epoch 12/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9979 - mean_absolute_error: 0.7533 - val_loss: 2.5415 - val_mean_absolute_error: 1.1962\n",
            "Epoch 13/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9972 - mean_absolute_error: 0.7529 - val_loss: 2.3409 - val_mean_absolute_error: 1.1232\n",
            "Epoch 14/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9969 - mean_absolute_error: 0.7530 - val_loss: 2.5138 - val_mean_absolute_error: 1.1876\n",
            "Epoch 15/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9957 - mean_absolute_error: 0.7528 - val_loss: 2.2099 - val_mean_absolute_error: 1.0762\n",
            "Epoch 16/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9965 - mean_absolute_error: 0.7531 - val_loss: 2.4681 - val_mean_absolute_error: 1.1717\n",
            "Epoch 17/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9959 - mean_absolute_error: 0.7529 - val_loss: 2.4433 - val_mean_absolute_error: 1.1615\n",
            "Epoch 18/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9952 - mean_absolute_error: 0.7529 - val_loss: 2.3445 - val_mean_absolute_error: 1.1268\n",
            "Epoch 19/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9950 - mean_absolute_error: 0.7529 - val_loss: 2.4667 - val_mean_absolute_error: 1.1679\n",
            "Epoch 20/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9951 - mean_absolute_error: 0.7527 - val_loss: 2.3063 - val_mean_absolute_error: 1.1110\n",
            "Epoch 21/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9945 - mean_absolute_error: 0.7528 - val_loss: 2.5300 - val_mean_absolute_error: 1.1919\n",
            "Epoch 22/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9945 - mean_absolute_error: 0.7529 - val_loss: 2.3615 - val_mean_absolute_error: 1.1320\n",
            "Epoch 23/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9943 - mean_absolute_error: 0.7529 - val_loss: 2.2061 - val_mean_absolute_error: 1.0781\n",
            "Epoch 24/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9933 - mean_absolute_error: 0.7528 - val_loss: 2.3237 - val_mean_absolute_error: 1.1159\n",
            "Epoch 25/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9930 - mean_absolute_error: 0.7526 - val_loss: 2.3522 - val_mean_absolute_error: 1.1282\n",
            "Epoch 26/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9933 - mean_absolute_error: 0.7532 - val_loss: 2.3508 - val_mean_absolute_error: 1.1290\n",
            "Epoch 27/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9928 - mean_absolute_error: 0.7529 - val_loss: 2.5111 - val_mean_absolute_error: 1.1849\n",
            "Epoch 28/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9932 - mean_absolute_error: 0.7530 - val_loss: 2.4126 - val_mean_absolute_error: 1.1515\n",
            "Epoch 29/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9917 - mean_absolute_error: 0.7524 - val_loss: 2.4207 - val_mean_absolute_error: 1.1524\n",
            "Epoch 30/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9922 - mean_absolute_error: 0.7526 - val_loss: 2.4510 - val_mean_absolute_error: 1.1637\n",
            "Epoch 31/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9915 - mean_absolute_error: 0.7527 - val_loss: 2.4052 - val_mean_absolute_error: 1.1491\n",
            "Epoch 32/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9921 - mean_absolute_error: 0.7527 - val_loss: 2.3601 - val_mean_absolute_error: 1.1307\n",
            "Epoch 33/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9917 - mean_absolute_error: 0.7527 - val_loss: 2.3726 - val_mean_absolute_error: 1.1376\n",
            "Epoch 34/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9914 - mean_absolute_error: 0.7527 - val_loss: 2.3869 - val_mean_absolute_error: 1.1400\n",
            "Epoch 35/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9912 - mean_absolute_error: 0.7523 - val_loss: 2.5076 - val_mean_absolute_error: 1.1845\n",
            "Epoch 36/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9910 - mean_absolute_error: 0.7524 - val_loss: 2.3727 - val_mean_absolute_error: 1.1369\n",
            "Epoch 37/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9911 - mean_absolute_error: 0.7525 - val_loss: 2.4817 - val_mean_absolute_error: 1.1757\n",
            "Epoch 38/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9907 - mean_absolute_error: 0.7526 - val_loss: 2.3739 - val_mean_absolute_error: 1.1374\n",
            "Epoch 39/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9893 - mean_absolute_error: 0.7522 - val_loss: 2.3445 - val_mean_absolute_error: 1.1274\n",
            "Epoch 40/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9900 - mean_absolute_error: 0.7526 - val_loss: 2.3696 - val_mean_absolute_error: 1.1352\n",
            "Epoch 41/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9903 - mean_absolute_error: 0.7526 - val_loss: 2.4366 - val_mean_absolute_error: 1.1593\n",
            "Epoch 42/50\n",
            "254362/254362 [==============================] - 4s 15us/step - loss: 0.9892 - mean_absolute_error: 0.7523 - val_loss: 2.4786 - val_mean_absolute_error: 1.1746\n",
            "Epoch 43/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9898 - mean_absolute_error: 0.7526 - val_loss: 2.5960 - val_mean_absolute_error: 1.2158\n",
            "Epoch 44/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9894 - mean_absolute_error: 0.7524 - val_loss: 2.5067 - val_mean_absolute_error: 1.1850\n",
            "Epoch 45/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9895 - mean_absolute_error: 0.7525 - val_loss: 2.4750 - val_mean_absolute_error: 1.1736\n",
            "Epoch 46/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9884 - mean_absolute_error: 0.7520 - val_loss: 2.2768 - val_mean_absolute_error: 1.1010\n",
            "Epoch 47/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9880 - mean_absolute_error: 0.7519 - val_loss: 2.2608 - val_mean_absolute_error: 1.0959\n",
            "Epoch 48/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9901 - mean_absolute_error: 0.7526 - val_loss: 2.3940 - val_mean_absolute_error: 1.1470\n",
            "Epoch 49/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9876 - mean_absolute_error: 0.7519 - val_loss: 2.3521 - val_mean_absolute_error: 1.1296\n",
            "Epoch 50/50\n",
            "254362/254362 [==============================] - 4s 14us/step - loss: 0.9884 - mean_absolute_error: 0.7521 - val_loss: 2.2820 - val_mean_absolute_error: 1.1026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0oNXD0wZjUJ",
        "colab_type": "code",
        "outputId": "b1240bf3-f868-45e3-e880-a2ddb603b1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_errors[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi0BN6UdZv0F",
        "colab_type": "code",
        "outputId": "89033a29-e95f-47d3-adc8-805914598682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "avg_train = [np.mean(i) for i in zip(*train_errors)]\n",
        "avg_val = [np.mean(i) for i in zip(*val_errors)]\n",
        "training_val_error_plotter(avg_train, avg_val)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcsChDHGmLAsQBhjjAnr/wOPRclpe7NJMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ1L1C19a7Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous*factor + point*(1-factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDkFfd1ja8ou",
        "colab_type": "code",
        "outputId": "e765214c-47a0-4294-fae1-fa7b4133cd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "smooth_avg_val = smooth_curve(avg_val, factor=0.9)\n",
        "training_val_error_plotter(avg_train, smooth_avg_val)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jccWyDYQ9YnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9bfb03b1-0d5e-47eb-eb1a-452c312872ec"
      },
      "source": [
        "training_val_error_plotter(train_mae, val_mae)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGONxFgiMMcbjLBAYY4zHWSAwxhiP+39/9taVaJFMogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-XtNzXSDDzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d181b314-f20a-4c1a-d924-7f14563ad465"
      },
      "source": [
        "test_mse, test_mae = model.evaluate(test_X, test_y)\n",
        "test_mae"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144006/144006 [==============================] - 10s 71us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.177268626610342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaGf8LsiD7DS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "81fc0ded-2f26-44e4-db10-d3101a5a2712"
      },
      "source": [
        "preds = model.predict(test_X)\n",
        "preds"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.972468 ],\n",
              "       [4.514878 ],\n",
              "       [4.486799 ],\n",
              "       ...,\n",
              "       [4.486799 ],\n",
              "       [4.486799 ],\n",
              "       [4.6450086]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nj5IaELEEAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eea5b8f5-6ee6-4c2c-b7db-612298ef8b45"
      },
      "source": [
        "train_df, val_df = split_train_val(train_df)\n",
        "(train_X, train_y), (val_X, val_y), (test_X, test_y)  = prep(train_df, val_df, test_df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (254361, 4)\n",
            "Test shape :  (144006, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}